{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook for training a neural process to predict simulated trajectories\n",
    "\n",
    "This notebook demonstrates how to sample user trajectories with varying user parameters from the pomdp-gridworld, and train a neural process to predict trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\") if USE_CUDA else torch.device(\"cpu\")\n",
    "\n",
    "#Set training to true if you want to train the model\n",
    "training = False\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing datasets\n",
    "\n",
    "The Sampler-class is used to extract the simulated user trajectories. Below is an example data processing pipeline using the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_context_and_target(trajectories):\n",
    "  '''\n",
    "  Given a set of trajectories, build the context and target tensors \n",
    "  to feed for the neural process\n",
    "  '''\n",
    "  xc, yc, xt, yt = [], [], [], []\n",
    "  traj_length = len(trajectories[0])\n",
    "  half_point = traj_length // 2\n",
    "  \n",
    "  for i, traj in enumerate(trajectories):\n",
    "\n",
    "    #Context is each context but the current index\n",
    "    context = [trajectories[j] for j in range(len(trajectories)) if j != i]\n",
    "    \n",
    "    #All except last\n",
    "    #context += [traj[:-1]]\n",
    "    \n",
    "    #Half\n",
    "    context += [traj[:half_point]]\n",
    "    context_s, context_a = zip(*[point for c in context for point in c])\n",
    "    \n",
    "    #Only predict the last step\n",
    "    #target_s, target_a = zip(*[traj[-1]])\n",
    "    \n",
    "    #Target last half\n",
    "    target_s, target_a = zip(*traj[half_point:])\n",
    "    \n",
    "    xc.append(torch.tensor(context_s, dtype=torch.float32))\n",
    "    yc.append(torch.tensor(context_a, dtype=torch.float32))\n",
    "    xt.append(torch.tensor(target_s, dtype=torch.float32))\n",
    "    yt.append(torch.tensor(target_a, dtype=torch.float32))\n",
    "    \n",
    "  # Stack tensors\n",
    "  xc = torch.stack(xc).to(device)\n",
    "  yc = torch.stack(yc).to(device)\n",
    "  xt = torch.stack(xt).to(device)\n",
    "  yt = torch.stack(yt).to(device)\n",
    "\n",
    "  return xc, yc, xt, yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(sampler, device = device):\n",
    "  user_params = sampler.generate_user_parameters()\n",
    "\n",
    "  n_trajectories = np.random.randint(low = 5, high = 10)\n",
    "\n",
    "  trajectories = sampler.generate_user_trajectories(n_trajectories, user_params)\n",
    "\n",
    "  xc, yc, xt, yt = build_context_and_target(trajectories)\n",
    "  \n",
    "  xc = xc.permute(0,2,1).to(device)\n",
    "  yc = yc.permute(0,2,1).to(device)\n",
    "  xt = xt.permute(0,2,1).to(device)\n",
    "  yt = yt.permute(0,2,1).to(device)\n",
    "  \n",
    "  return xc, yc, xt, yt, user_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sampler can be used to define the parameters of GridWorld, which is then passed to\n",
    "the data processing pipeline. Here we use a fully observable gridworld where the agent knows the goal position at initialization. This can be turned off, but good results are not guaranteed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3)\n",
      "Shape of xc: torch.Size([8, 2, 75]), yc: torch.Size([8, 5, 75]), xt: torch.Size([8, 2, 5]), yt: torch.Size([8, 5, 5])\n",
      "Device of xc: cuda:0, yc: cuda:0, xt: cuda:0, yt: cuda:0\n",
      "First sequence context:\n",
      "[[ 1.  2.  3.  4.  4.  4.  4.  4.  4.  4.  3.  4.  3.  4.  4.  4.  3.  4.\n",
      "   4.  4.  6.  5.  5.  4.  4.  4.  4.  4.  4.  4.  9.  8.  8.  7.  6.  5.\n",
      "   4.  4.  4.  4.  5.  4.  4.  4.  4.  4.  4.  4.  4.  4.  8.  8.  7.  6.\n",
      "   5.  4.  4.  4.  4.  4.  5.  5.  4.  4.  4.  4.  4.  4.  3.  4.  6.  5.\n",
      "   4.  4.  4.]\n",
      " [ 4.  4.  4.  4.  3.  3.  3.  3.  3.  3.  8.  8.  8.  8.  7.  6.  6.  6.\n",
      "   5.  4.  3.  3.  2.  2.  3.  3.  3.  3.  3.  3.  8.  8.  9.  9.  9.  9.\n",
      "   9.  8.  7.  6.  8.  8.  7.  6.  5.  4.  3.  3.  3.  3.  2.  3.  3.  3.\n",
      "   3.  3.  3.  3.  3.  3.  9. 10. 10.  9.  8.  7.  6.  5.  5.  5.  8.  8.\n",
      "   8.  7.  6.]]\n",
      "Goal position: (4, 3)\n"
     ]
    }
   ],
   "source": [
    "from src.utils.sampler import Sampler\n",
    "\n",
    "GRID_SIZE = 10\n",
    "AGENT_VIEW_SIZE = 3\n",
    "TRAJ_LENGTH = 10\n",
    "\n",
    "sampler = Sampler(grid_size = GRID_SIZE, agent_view_size = AGENT_VIEW_SIZE, traj_length = TRAJ_LENGTH, fixed_goal = True, fully_observable = True)\n",
    "xc, yc, xt, yt, user_params = get_batch(sampler)\n",
    "\n",
    "print(user_params[\"goal_position\"])\n",
    "\n",
    "print(f\"Shape of xc: {xc.shape}, yc: {yc.shape}, xt: {xt.shape}, yt: {yt.shape}\")\n",
    "print(f\"Device of xc: {xc.device}, yc: {yc.device}, xt: {xt.device}, yt: {yt.device}\")\n",
    "\n",
    "print(f\"First sequence context:\\n{np.array(xc[0].to('cpu'))}\")\n",
    "print(f\"Goal position: {user_params['goal_position']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualitative trajectory evaluation\n",
    "\n",
    "The following functions help measuring the quality of the predicted trajectory sequences.\n",
    "\n",
    "Given the one-hot encoded actions, the trajectories are constructed either from (0,0) or from the last coordinates\n",
    "of the context set. The predictions and true trajectories are compared by the manhattan distance in each time step, which is fixed\n",
    "in the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 5]) torch.Size([9, 5])\n",
      "Predictions: tensor([[2, 2, 3, 3, 3],\n",
      "        [3, 3, 3, 3, 3],\n",
      "        [3, 3, 3, 3, 3],\n",
      "        [2, 2, 2, 2, 2],\n",
      "        [3, 2, 2, 2, 3],\n",
      "        [3, 3, 3, 3, 3],\n",
      "        [3, 3, 3, 3, 3],\n",
      "        [3, 3, 3, 3, 3],\n",
      "        [2, 3, 3, 3, 3]], device='cuda:0')\n",
      "True actions: tensor([[3, 3, 3, 4, 4],\n",
      "        [2, 4, 4, 4, 4],\n",
      "        [3, 4, 4, 4, 4],\n",
      "        [0, 0, 3, 3, 3],\n",
      "        [0, 0, 3, 3, 3],\n",
      "        [2, 4, 4, 4, 4],\n",
      "        [4, 4, 4, 4, 4],\n",
      "        [1, 0, 2, 2, 2],\n",
      "        [3, 3, 4, 4, 4]], device='cuda:0')\n",
      "Manhattan distance: tensor([[ 2.,  4.,  4.,  3.,  2.],\n",
      "        [ 2.,  3.,  4.,  5.,  6.],\n",
      "        [ 0.,  1.,  2.,  3.,  4.],\n",
      "        [ 2.,  4.,  6.,  8., 10.],\n",
      "        [ 2.,  4.,  4.,  6.,  6.],\n",
      "        [ 2.,  3.,  4.,  5.,  6.],\n",
      "        [ 1.,  2.,  3.,  4.,  5.],\n",
      "        [ 2.,  4.,  4.,  6.,  8.],\n",
      "        [ 2.,  2.,  1.,  2.,  3.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from minigrid.core.constants import DIR_TO_VEC\n",
    "#The last action corresponding to stationary\n",
    "DIR_TO_VEC =  DIR_TO_VEC + [(0, 0)]\n",
    "\n",
    "def construct_trajectory(actions, start_pos = None):\n",
    "    \"\"\"\n",
    "    Constructs a trajectory from a sequence of actions\n",
    "    \"\"\"\n",
    "    \n",
    "    mapping = torch.tensor(DIR_TO_VEC, dtype = torch.float32, device = actions.device)\n",
    "    \n",
    "    batch_size, seq_length = actions.shape\n",
    "    \n",
    "    trajectory = torch.zeros(batch_size, 2, seq_length, device = actions.device)\n",
    "    \n",
    "    if start_pos is not None:\n",
    "        prev = start_pos\n",
    "    else:\n",
    "        prev = torch.zeros(batch_size, 2, device = actions.device)\n",
    "        \n",
    "    for i in range(seq_length):\n",
    "        action_indices = actions[:, i]\n",
    "        change = mapping[action_indices]\n",
    "        trajectory[:, :, i] = prev + change\n",
    "        prev = trajectory[:, :, i]\n",
    "    \n",
    "    return trajectory\n",
    "    \n",
    "def construct_and_calc_l1_dist(yt, predictions, xc=None):\n",
    "    '''\n",
    "    Calculates the Manhattan distance between the predicted and true trajectories.\n",
    "    '''\n",
    "    # Construct trajectories\n",
    "    start_pos = xc[:, :, -1] if xc is not None else None\n",
    "    true_trajectory = construct_trajectory(yt, start_pos)\n",
    "    pred_trajectory = construct_trajectory(predictions, start_pos)\n",
    "    \n",
    "    # Calculate Manhattan distance at each timestep\n",
    "    distances = torch.abs(pred_trajectory - true_trajectory).sum(dim = 1)\n",
    "    \n",
    "    return distances\n",
    "\n",
    "# Test\n",
    "xc, yc, xt, yt, _ = get_batch(sampler)\n",
    "\n",
    "import neuralprocesses.torch as nps\n",
    "import torch.nn.functional as F\n",
    "\n",
    "agnp = nps.construct_agnp(dim_x = 2, dim_y = 5, likelihood = \"het\").to(device)\n",
    "dist = agnp(xc, yc, xt).mean\n",
    "preds = F.softmax(dist, dim=-2)\n",
    "true_actions = yt.argmax(-2)\n",
    "predictions = preds.argmax(-2)\n",
    "print(true_actions.shape, predictions.shape)\n",
    "distance = construct_and_calc_l1_dist(true_actions, predictions)\n",
    "\n",
    "\n",
    "print(f\"Predictions: {predictions}\")\n",
    "print(f\"True actions: {true_actions}\")\n",
    "print(f\"Manhattan distance: {distance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt to calculate the kl-divergence\n",
    "\n",
    "Does not seem to be currently working. The implementation is based on neuralprocesses library code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from neuralprocesses.coding import code,code_track, recode_stochastic\n",
    "from neuralprocesses.model.util import compress_contexts\n",
    "from neuralprocesses import _dispatch\n",
    "from neuralprocesses.parallel import Parallel\n",
    "from neuralprocesses.dist import AbstractDistribution\n",
    "\n",
    "@_dispatch\n",
    "def _kl(q: AbstractDistribution, p: AbstractDistribution):\n",
    "    return q.kl(p)\n",
    "\n",
    "\n",
    "@_dispatch\n",
    "def _kl(q: Parallel, p: Parallel):\n",
    "    return sum([_kl(qi, pi) for qi, pi in zip(q, p)])\n",
    "\n",
    "\n",
    "def calc_kl_divergence(model, xc, yc, xt, yt, dtype_lik = None):\n",
    "  \n",
    "    if not dtype_lik:\n",
    "      dtype_lik = torch.float32\n",
    "    \n",
    "    all_x = torch.cat([xc, xt], dim = -1)\n",
    "    all_y = torch.cat([yc, yt], dim = -1)\n",
    "      \n",
    "    xz, pz, h = code_track(model.encoder, xc, yc, xt, root=True)\n",
    "    \n",
    "    qz  = recode_stochastic(model.encoder, pz, all_x, all_y, h, root=True, dtype_lik = dtype_lik)\n",
    "    \n",
    "    kl = _kl(qz, pz)\n",
    "    \n",
    "    return kl\n",
    "\n",
    "kl = calc_kl_divergence(agnp, xc, yc, xt, yt)\n",
    "print(kl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop\n",
    "\n",
    "The training loop maximizes the log-likelihood of the categorical distribution of 5-actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 1.6040, Accuracy: 0.3500 mean distance difference: 11.3750, Final distance difference: 3.2500\n",
      "Iteration 100, Loss: 1.5864, Accuracy: 0.2444 mean distance difference: 9.0000, Final distance difference: 2.2222\n",
      "Iteration 200, Loss: 1.3910, Accuracy: 0.5000 mean distance difference: 8.6667, Final distance difference: 2.5000\n",
      "Iteration 300, Loss: 1.8844, Accuracy: 0.1250 mean distance difference: 10.3750, Final distance difference: 2.8750\n",
      "Iteration 400, Loss: 1.2880, Accuracy: 0.5000 mean distance difference: 6.7500, Final distance difference: 2.2500\n",
      "Iteration 500, Loss: 1.2771, Accuracy: 0.5250 mean distance difference: 7.5000, Final distance difference: 2.1250\n",
      "Iteration 600, Loss: 1.3550, Accuracy: 0.5000 mean distance difference: 8.5000, Final distance difference: 2.5000\n",
      "Iteration 700, Loss: 1.3751, Accuracy: 0.4000 mean distance difference: 10.0000, Final distance difference: 3.0000\n",
      "Iteration 800, Loss: 1.3803, Accuracy: 0.5600 mean distance difference: 4.4000, Final distance difference: 1.0000\n",
      "Iteration 900, Loss: 1.6387, Accuracy: 0.2444 mean distance difference: 9.3333, Final distance difference: 2.6667\n",
      "Iteration 1000, Loss: 1.4745, Accuracy: 0.3750 mean distance difference: 8.3750, Final distance difference: 2.3750\n",
      "Iteration 1100, Loss: 1.5726, Accuracy: 0.3667 mean distance difference: 7.3333, Final distance difference: 1.8333\n",
      "Iteration 1200, Loss: 1.3839, Accuracy: 0.3500 mean distance difference: 9.0000, Final distance difference: 2.7500\n",
      "Iteration 1300, Loss: 1.2664, Accuracy: 0.4800 mean distance difference: 9.4000, Final distance difference: 2.6000\n",
      "Iteration 1400, Loss: 1.6945, Accuracy: 0.1600 mean distance difference: 6.6000, Final distance difference: 1.8000\n",
      "Iteration 1500, Loss: 1.6343, Accuracy: 0.3500 mean distance difference: 8.6250, Final distance difference: 2.5000\n",
      "Iteration 1600, Loss: 1.4991, Accuracy: 0.4286 mean distance difference: 9.4286, Final distance difference: 2.2857\n",
      "Iteration 1700, Loss: 1.2695, Accuracy: 0.4222 mean distance difference: 8.5556, Final distance difference: 2.6667\n",
      "Iteration 1800, Loss: 1.6880, Accuracy: 0.1333 mean distance difference: 12.3333, Final distance difference: 4.0000\n",
      "Iteration 1900, Loss: 1.0920, Accuracy: 0.6333 mean distance difference: 3.6667, Final distance difference: 1.1667\n",
      "Iteration 2000, Loss: 0.9585, Accuracy: 0.7143 mean distance difference: 4.7143, Final distance difference: 1.1429\n",
      "Iteration 2100, Loss: 1.4620, Accuracy: 0.4250 mean distance difference: 5.2500, Final distance difference: 1.6250\n",
      "Iteration 2200, Loss: 0.7911, Accuracy: 0.7556 mean distance difference: 5.0000, Final distance difference: 1.2222\n",
      "Iteration 2300, Loss: 1.1651, Accuracy: 0.5250 mean distance difference: 6.2500, Final distance difference: 1.8750\n",
      "Iteration 2400, Loss: 1.4096, Accuracy: 0.4889 mean distance difference: 11.2222, Final distance difference: 3.2222\n",
      "Iteration 2500, Loss: 1.7011, Accuracy: 0.1333 mean distance difference: 11.3333, Final distance difference: 3.5000\n",
      "Iteration 2600, Loss: 1.1438, Accuracy: 0.6667 mean distance difference: 7.6667, Final distance difference: 2.0000\n",
      "Iteration 2700, Loss: 0.6592, Accuracy: 0.8500 mean distance difference: 3.0000, Final distance difference: 0.7500\n",
      "Iteration 2800, Loss: 1.4882, Accuracy: 0.4500 mean distance difference: 6.6250, Final distance difference: 2.2500\n",
      "Iteration 2900, Loss: 0.6638, Accuracy: 0.7667 mean distance difference: 6.0000, Final distance difference: 1.6667\n",
      "Iteration 3000, Loss: 1.6028, Accuracy: 0.3200 mean distance difference: 12.2000, Final distance difference: 3.4000\n",
      "Iteration 3100, Loss: 1.4294, Accuracy: 0.3000 mean distance difference: 13.8750, Final distance difference: 3.8750\n",
      "Iteration 3200, Loss: 0.9863, Accuracy: 0.7333 mean distance difference: 4.1667, Final distance difference: 1.1667\n",
      "Iteration 3300, Loss: 1.4481, Accuracy: 0.1500 mean distance difference: 15.1250, Final distance difference: 4.8750\n",
      "Iteration 3400, Loss: 0.5781, Accuracy: 0.9200 mean distance difference: 3.0000, Final distance difference: 0.6000\n",
      "Iteration 3500, Loss: 0.8969, Accuracy: 0.6250 mean distance difference: 8.2500, Final distance difference: 2.3750\n",
      "Iteration 3600, Loss: 1.4171, Accuracy: 0.1556 mean distance difference: 11.7778, Final distance difference: 3.5556\n",
      "Iteration 3700, Loss: 1.4637, Accuracy: 0.4800 mean distance difference: 6.2000, Final distance difference: 2.2000\n",
      "Iteration 3800, Loss: 1.1185, Accuracy: 0.6000 mean distance difference: 6.7778, Final distance difference: 2.0000\n",
      "Iteration 3900, Loss: 0.8324, Accuracy: 0.6000 mean distance difference: 6.4000, Final distance difference: 1.8000\n",
      "Iteration 4000, Loss: 0.6684, Accuracy: 0.9000 mean distance difference: 1.7500, Final distance difference: 0.5000\n",
      "Iteration 4100, Loss: 1.5834, Accuracy: 0.1600 mean distance difference: 13.0000, Final distance difference: 2.8000\n",
      "Iteration 4200, Loss: 0.7722, Accuracy: 0.7600 mean distance difference: 6.0000, Final distance difference: 1.6000\n",
      "Iteration 4300, Loss: 1.2971, Accuracy: 0.4857 mean distance difference: 9.1429, Final distance difference: 2.1429\n",
      "Iteration 4400, Loss: 0.7794, Accuracy: 0.6750 mean distance difference: 5.5000, Final distance difference: 0.7500\n",
      "Iteration 4500, Loss: 0.8059, Accuracy: 0.6333 mean distance difference: 5.0000, Final distance difference: 1.1667\n",
      "Iteration 4600, Loss: 0.8265, Accuracy: 0.7600 mean distance difference: 4.4000, Final distance difference: 1.2000\n",
      "Iteration 4700, Loss: 0.7236, Accuracy: 0.7429 mean distance difference: 8.4286, Final distance difference: 2.4286\n",
      "Iteration 4800, Loss: 0.7780, Accuracy: 0.6250 mean distance difference: 5.6250, Final distance difference: 1.8750\n",
      "Iteration 4900, Loss: 1.0923, Accuracy: 0.5778 mean distance difference: 6.7778, Final distance difference: 1.4444\n",
      "Iteration 5000, Loss: 0.8755, Accuracy: 0.7200 mean distance difference: 5.2000, Final distance difference: 1.4000\n",
      "Iteration 5100, Loss: 1.6694, Accuracy: 0.3600 mean distance difference: 8.8000, Final distance difference: 2.4000\n",
      "Iteration 5200, Loss: 0.5546, Accuracy: 0.8000 mean distance difference: 6.4000, Final distance difference: 1.4000\n",
      "Iteration 5300, Loss: 0.9444, Accuracy: 0.7667 mean distance difference: 3.0000, Final distance difference: 1.5000\n",
      "Iteration 5400, Loss: 0.6895, Accuracy: 0.7429 mean distance difference: 4.1429, Final distance difference: 1.2857\n",
      "Iteration 5500, Loss: 0.8689, Accuracy: 0.6750 mean distance difference: 7.1250, Final distance difference: 2.2500\n",
      "Iteration 5600, Loss: 0.6643, Accuracy: 0.7750 mean distance difference: 4.0000, Final distance difference: 1.3750\n",
      "Iteration 5700, Loss: 0.7279, Accuracy: 0.8400 mean distance difference: 1.4000, Final distance difference: 0.4000\n",
      "Iteration 5800, Loss: 0.8114, Accuracy: 0.6667 mean distance difference: 6.6667, Final distance difference: 2.0000\n",
      "Iteration 5900, Loss: 0.7516, Accuracy: 0.8000 mean distance difference: 5.8000, Final distance difference: 1.2000\n",
      "Iteration 6000, Loss: 0.6084, Accuracy: 0.8000 mean distance difference: 3.0000, Final distance difference: 1.0000\n",
      "Iteration 6100, Loss: 1.2020, Accuracy: 0.5667 mean distance difference: 4.6667, Final distance difference: 1.1667\n",
      "Iteration 6200, Loss: 0.6008, Accuracy: 0.8000 mean distance difference: 3.6000, Final distance difference: 1.6000\n",
      "Iteration 6300, Loss: 0.4725, Accuracy: 0.8000 mean distance difference: 3.6000, Final distance difference: 0.8000\n",
      "Iteration 6400, Loss: 0.7099, Accuracy: 0.7000 mean distance difference: 5.1667, Final distance difference: 1.3333\n",
      "Iteration 6500, Loss: 0.8336, Accuracy: 0.8500 mean distance difference: 1.8750, Final distance difference: 0.5000\n",
      "Iteration 6600, Loss: 0.9391, Accuracy: 0.7000 mean distance difference: 5.1250, Final distance difference: 1.0000\n",
      "Iteration 6700, Loss: 0.6861, Accuracy: 0.7500 mean distance difference: 6.2500, Final distance difference: 1.7500\n",
      "Iteration 6800, Loss: 0.9871, Accuracy: 0.6667 mean distance difference: 8.5000, Final distance difference: 2.5000\n",
      "Iteration 6900, Loss: 0.5473, Accuracy: 0.8250 mean distance difference: 4.3750, Final distance difference: 0.8750\n",
      "Iteration 7000, Loss: 0.8362, Accuracy: 0.7778 mean distance difference: 3.4444, Final distance difference: 1.1111\n",
      "Iteration 7100, Loss: 1.2767, Accuracy: 0.6800 mean distance difference: 6.8000, Final distance difference: 2.0000\n",
      "Iteration 7200, Loss: 0.8968, Accuracy: 0.6571 mean distance difference: 6.0000, Final distance difference: 1.8571\n",
      "Iteration 7300, Loss: 0.8944, Accuracy: 0.6750 mean distance difference: 6.6250, Final distance difference: 2.1250\n",
      "Iteration 7400, Loss: 0.8469, Accuracy: 0.2667 mean distance difference: 11.3333, Final distance difference: 3.8333\n",
      "Iteration 7500, Loss: 0.8196, Accuracy: 0.5333 mean distance difference: 8.0000, Final distance difference: 2.6667\n",
      "Iteration 7600, Loss: 0.7441, Accuracy: 0.8000 mean distance difference: 2.4444, Final distance difference: 0.8889\n",
      "Iteration 7700, Loss: 1.2615, Accuracy: 0.5600 mean distance difference: 5.0000, Final distance difference: 2.0000\n",
      "Iteration 7800, Loss: 1.2942, Accuracy: 0.5333 mean distance difference: 10.8333, Final distance difference: 3.0000\n",
      "Iteration 7900, Loss: 0.8642, Accuracy: 0.6800 mean distance difference: 8.6000, Final distance difference: 2.0000\n",
      "Iteration 8000, Loss: 1.4444, Accuracy: 0.6000 mean distance difference: 4.4286, Final distance difference: 2.0000\n",
      "Iteration 8100, Loss: 0.9720, Accuracy: 0.6250 mean distance difference: 5.8750, Final distance difference: 2.2500\n",
      "Iteration 8200, Loss: 0.5109, Accuracy: 0.8667 mean distance difference: 2.4444, Final distance difference: 0.6667\n",
      "Iteration 8300, Loss: 0.8081, Accuracy: 0.8000 mean distance difference: 4.8333, Final distance difference: 1.0000\n",
      "Iteration 8400, Loss: 0.3698, Accuracy: 0.9143 mean distance difference: 1.7143, Final distance difference: 0.2857\n",
      "Iteration 8500, Loss: 0.5088, Accuracy: 0.8857 mean distance difference: 2.1429, Final distance difference: 0.5714\n",
      "Iteration 8600, Loss: 0.5019, Accuracy: 0.9143 mean distance difference: 2.2857, Final distance difference: 0.5714\n",
      "Iteration 8700, Loss: 0.5418, Accuracy: 0.8667 mean distance difference: 2.3333, Final distance difference: 1.0000\n",
      "Iteration 8800, Loss: 0.8424, Accuracy: 0.6222 mean distance difference: 5.8889, Final distance difference: 1.6667\n",
      "Iteration 8900, Loss: 0.6350, Accuracy: 0.8222 mean distance difference: 3.1111, Final distance difference: 1.4444\n",
      "Iteration 9000, Loss: 0.7172, Accuracy: 0.7714 mean distance difference: 3.4286, Final distance difference: 1.1429\n",
      "Iteration 9100, Loss: 0.8878, Accuracy: 0.8571 mean distance difference: 3.2857, Final distance difference: 0.7143\n",
      "Iteration 9200, Loss: 0.6273, Accuracy: 0.8667 mean distance difference: 1.3333, Final distance difference: 0.6667\n",
      "Iteration 9300, Loss: 0.3775, Accuracy: 0.9000 mean distance difference: 1.8750, Final distance difference: 0.5000\n",
      "Iteration 9400, Loss: 0.9585, Accuracy: 0.5667 mean distance difference: 8.3333, Final distance difference: 2.6667\n",
      "Iteration 9500, Loss: 0.5871, Accuracy: 0.7750 mean distance difference: 4.2500, Final distance difference: 1.2500\n",
      "Iteration 9600, Loss: 0.9037, Accuracy: 0.5600 mean distance difference: 8.0000, Final distance difference: 2.2000\n",
      "Iteration 9700, Loss: 0.9221, Accuracy: 0.6333 mean distance difference: 4.3333, Final distance difference: 2.0000\n",
      "Iteration 9800, Loss: 0.8098, Accuracy: 0.6800 mean distance difference: 5.6000, Final distance difference: 1.6000\n",
      "Iteration 9900, Loss: 0.8189, Accuracy: 0.7111 mean distance difference: 5.2222, Final distance difference: 1.5556\n",
      "Iteration 10000, Loss: 0.9685, Accuracy: 0.7667 mean distance difference: 4.3333, Final distance difference: 1.3333\n",
      "Iteration 10100, Loss: 0.7340, Accuracy: 0.8000 mean distance difference: 2.6667, Final distance difference: 1.0000\n",
      "Iteration 10200, Loss: 0.5313, Accuracy: 0.7667 mean distance difference: 3.0000, Final distance difference: 1.5000\n",
      "Iteration 10300, Loss: 0.6948, Accuracy: 0.8000 mean distance difference: 3.8750, Final distance difference: 0.8750\n",
      "Iteration 10400, Loss: 0.3688, Accuracy: 0.8000 mean distance difference: 3.0000, Final distance difference: 0.8000\n",
      "Iteration 10500, Loss: 0.5868, Accuracy: 0.8000 mean distance difference: 3.1667, Final distance difference: 1.1667\n",
      "Iteration 10600, Loss: 0.9124, Accuracy: 0.8250 mean distance difference: 2.7500, Final distance difference: 0.7500\n",
      "Iteration 10700, Loss: 0.5269, Accuracy: 0.8333 mean distance difference: 2.5000, Final distance difference: 0.6667\n",
      "Iteration 10800, Loss: 1.5639, Accuracy: 0.4000 mean distance difference: 9.5000, Final distance difference: 3.5000\n",
      "Iteration 10900, Loss: 0.7673, Accuracy: 0.7500 mean distance difference: 4.2500, Final distance difference: 1.3750\n",
      "Iteration 11000, Loss: 0.7987, Accuracy: 0.7714 mean distance difference: 5.4286, Final distance difference: 1.4286\n",
      "Iteration 11100, Loss: 0.5346, Accuracy: 0.8571 mean distance difference: 2.4286, Final distance difference: 0.7143\n",
      "Iteration 11200, Loss: 0.4609, Accuracy: 0.8571 mean distance difference: 2.1429, Final distance difference: 0.7143\n",
      "Iteration 11300, Loss: 0.7946, Accuracy: 0.6444 mean distance difference: 4.5556, Final distance difference: 1.6667\n",
      "Iteration 11400, Loss: 0.5602, Accuracy: 0.8500 mean distance difference: 2.2500, Final distance difference: 0.7500\n",
      "Iteration 11500, Loss: 1.4876, Accuracy: 0.4400 mean distance difference: 10.6000, Final distance difference: 4.2000\n",
      "Iteration 11600, Loss: 0.7677, Accuracy: 0.7250 mean distance difference: 2.8750, Final distance difference: 0.8750\n",
      "Iteration 11700, Loss: 0.6021, Accuracy: 0.6000 mean distance difference: 5.2500, Final distance difference: 2.1250\n",
      "Iteration 11800, Loss: 0.4873, Accuracy: 0.8000 mean distance difference: 3.1250, Final distance difference: 1.0000\n",
      "Iteration 11900, Loss: 0.6860, Accuracy: 0.8667 mean distance difference: 3.0000, Final distance difference: 0.8333\n",
      "Iteration 12000, Loss: 0.8690, Accuracy: 0.5500 mean distance difference: 8.7500, Final distance difference: 2.7500\n",
      "Iteration 12100, Loss: 0.6400, Accuracy: 0.7200 mean distance difference: 3.6000, Final distance difference: 1.4000\n",
      "Iteration 12200, Loss: 0.4802, Accuracy: 0.7667 mean distance difference: 4.1667, Final distance difference: 1.5000\n",
      "Iteration 12300, Loss: 0.7789, Accuracy: 0.6889 mean distance difference: 4.2222, Final distance difference: 1.5556\n",
      "Iteration 12400, Loss: 0.6503, Accuracy: 0.8250 mean distance difference: 1.3750, Final distance difference: 0.6250\n",
      "Iteration 12500, Loss: 0.6882, Accuracy: 0.8000 mean distance difference: 3.6667, Final distance difference: 1.1111\n",
      "Iteration 12600, Loss: 0.4216, Accuracy: 0.8857 mean distance difference: 2.5714, Final distance difference: 0.5714\n",
      "Iteration 12700, Loss: 0.6440, Accuracy: 0.8222 mean distance difference: 3.1111, Final distance difference: 1.0000\n",
      "Iteration 12800, Loss: 0.8430, Accuracy: 0.7000 mean distance difference: 5.5000, Final distance difference: 1.6250\n",
      "Iteration 12900, Loss: 0.9138, Accuracy: 0.7667 mean distance difference: 4.5000, Final distance difference: 1.1667\n",
      "Iteration 13000, Loss: 0.6500, Accuracy: 0.8000 mean distance difference: 4.2000, Final distance difference: 0.8000\n",
      "Iteration 13100, Loss: 0.8816, Accuracy: 0.7333 mean distance difference: 4.6667, Final distance difference: 1.0000\n",
      "Iteration 13200, Loss: 0.5413, Accuracy: 0.8400 mean distance difference: 5.0000, Final distance difference: 1.0000\n",
      "Iteration 13300, Loss: 0.3984, Accuracy: 0.8857 mean distance difference: 2.0000, Final distance difference: 0.5714\n",
      "Iteration 13400, Loss: 0.5428, Accuracy: 0.9200 mean distance difference: 2.6000, Final distance difference: 0.6000\n",
      "Iteration 13500, Loss: 1.5001, Accuracy: 0.4444 mean distance difference: 9.6667, Final distance difference: 3.4444\n",
      "Iteration 13600, Loss: 0.3313, Accuracy: 0.9500 mean distance difference: 1.5000, Final distance difference: 0.3750\n",
      "Iteration 13700, Loss: 1.0348, Accuracy: 0.5556 mean distance difference: 6.7778, Final distance difference: 2.1111\n",
      "Iteration 13800, Loss: 0.6525, Accuracy: 0.8571 mean distance difference: 4.1429, Final distance difference: 1.1429\n",
      "Iteration 13900, Loss: 0.6949, Accuracy: 0.8000 mean distance difference: 5.4000, Final distance difference: 1.0000\n",
      "Iteration 14000, Loss: 0.5385, Accuracy: 0.8667 mean distance difference: 2.0000, Final distance difference: 0.6667\n",
      "Iteration 14100, Loss: 0.8268, Accuracy: 0.6857 mean distance difference: 6.1429, Final distance difference: 1.7143\n",
      "Iteration 14200, Loss: 1.5216, Accuracy: 0.3200 mean distance difference: 13.4000, Final distance difference: 4.8000\n",
      "Iteration 14300, Loss: 0.7100, Accuracy: 0.8222 mean distance difference: 4.2222, Final distance difference: 0.7778\n",
      "Iteration 14400, Loss: 0.6726, Accuracy: 0.8000 mean distance difference: 4.3750, Final distance difference: 1.0000\n",
      "Iteration 14500, Loss: 0.7742, Accuracy: 0.6889 mean distance difference: 4.1111, Final distance difference: 1.4444\n",
      "Iteration 14600, Loss: 0.4912, Accuracy: 0.9143 mean distance difference: 1.7143, Final distance difference: 0.4286\n",
      "Iteration 14700, Loss: 0.2750, Accuracy: 1.0000 mean distance difference: 0.0000, Final distance difference: 0.0000\n",
      "Iteration 14800, Loss: 0.6776, Accuracy: 0.8500 mean distance difference: 4.1250, Final distance difference: 1.1250\n",
      "Iteration 14900, Loss: 0.5119, Accuracy: 0.8286 mean distance difference: 2.5714, Final distance difference: 0.7143\n",
      "Iteration 15000, Loss: 0.3696, Accuracy: 0.8500 mean distance difference: 2.8750, Final distance difference: 0.6250\n",
      "Iteration 15100, Loss: 0.6701, Accuracy: 0.8444 mean distance difference: 2.6667, Final distance difference: 0.7778\n",
      "Iteration 15200, Loss: 0.8801, Accuracy: 0.8000 mean distance difference: 5.0000, Final distance difference: 1.2857\n",
      "Iteration 15300, Loss: 0.3693, Accuracy: 0.9000 mean distance difference: 1.6667, Final distance difference: 0.5000\n",
      "Iteration 15400, Loss: 0.6304, Accuracy: 0.8000 mean distance difference: 3.5000, Final distance difference: 1.1250\n",
      "Iteration 15500, Loss: 0.2786, Accuracy: 0.9556 mean distance difference: 0.6667, Final distance difference: 0.2222\n",
      "Iteration 15600, Loss: 1.3427, Accuracy: 0.5667 mean distance difference: 7.3333, Final distance difference: 2.1667\n",
      "Iteration 15700, Loss: 0.6204, Accuracy: 0.8222 mean distance difference: 4.5556, Final distance difference: 1.2222\n",
      "Iteration 15800, Loss: 1.0463, Accuracy: 0.5143 mean distance difference: 15.2857, Final distance difference: 4.1429\n",
      "Iteration 15900, Loss: 0.5075, Accuracy: 0.8889 mean distance difference: 2.6667, Final distance difference: 0.5556\n",
      "Iteration 16000, Loss: 0.6071, Accuracy: 0.7600 mean distance difference: 3.6000, Final distance difference: 1.2000\n",
      "Iteration 16100, Loss: 0.6825, Accuracy: 0.7000 mean distance difference: 3.1667, Final distance difference: 1.0000\n",
      "Iteration 16200, Loss: 1.1427, Accuracy: 0.5333 mean distance difference: 8.0000, Final distance difference: 2.8333\n",
      "Iteration 16300, Loss: 0.6577, Accuracy: 0.7200 mean distance difference: 6.2000, Final distance difference: 1.6000\n",
      "Iteration 16400, Loss: 0.4619, Accuracy: 0.9250 mean distance difference: 0.8750, Final distance difference: 0.3750\n",
      "Iteration 16500, Loss: 0.4287, Accuracy: 0.8800 mean distance difference: 2.4000, Final distance difference: 0.6000\n",
      "Iteration 16600, Loss: 0.4847, Accuracy: 0.8857 mean distance difference: 2.1429, Final distance difference: 0.5714\n",
      "Iteration 16700, Loss: 0.5603, Accuracy: 0.8500 mean distance difference: 3.3750, Final distance difference: 1.0000\n",
      "Iteration 16800, Loss: 0.4861, Accuracy: 0.8571 mean distance difference: 3.2857, Final distance difference: 0.8571\n",
      "Iteration 16900, Loss: 0.3604, Accuracy: 0.9600 mean distance difference: 0.2000, Final distance difference: 0.2000\n",
      "Iteration 17000, Loss: 0.4896, Accuracy: 0.8667 mean distance difference: 2.6667, Final distance difference: 1.0000\n",
      "Iteration 17100, Loss: 0.3373, Accuracy: 0.9600 mean distance difference: 0.8000, Final distance difference: 0.4000\n",
      "Iteration 17200, Loss: 0.6131, Accuracy: 0.8000 mean distance difference: 3.8000, Final distance difference: 0.8000\n",
      "Iteration 17300, Loss: 0.5447, Accuracy: 0.7778 mean distance difference: 3.1111, Final distance difference: 1.1111\n",
      "Iteration 17400, Loss: 0.3959, Accuracy: 0.9143 mean distance difference: 1.5714, Final distance difference: 0.5714\n",
      "Iteration 17500, Loss: 0.4289, Accuracy: 0.8667 mean distance difference: 2.3333, Final distance difference: 0.6667\n",
      "Iteration 17600, Loss: 0.4272, Accuracy: 0.8571 mean distance difference: 2.4286, Final distance difference: 0.7143\n",
      "Iteration 17700, Loss: 0.6683, Accuracy: 0.7750 mean distance difference: 5.5000, Final distance difference: 1.5000\n",
      "Iteration 17800, Loss: 0.5922, Accuracy: 0.7600 mean distance difference: 3.8000, Final distance difference: 1.4000\n",
      "Iteration 17900, Loss: 0.4498, Accuracy: 0.8750 mean distance difference: 1.5000, Final distance difference: 0.6250\n",
      "Iteration 18000, Loss: 0.6319, Accuracy: 0.8222 mean distance difference: 3.7778, Final distance difference: 1.1111\n",
      "Iteration 18100, Loss: 0.9117, Accuracy: 0.6800 mean distance difference: 6.0000, Final distance difference: 1.2000\n",
      "Iteration 18200, Loss: 0.6590, Accuracy: 0.8000 mean distance difference: 4.8000, Final distance difference: 1.4000\n",
      "Iteration 18300, Loss: 1.0539, Accuracy: 0.7200 mean distance difference: 2.6000, Final distance difference: 1.2000\n",
      "Iteration 18400, Loss: 0.8244, Accuracy: 0.6571 mean distance difference: 7.0000, Final distance difference: 1.8571\n",
      "Iteration 18500, Loss: 0.6073, Accuracy: 0.7143 mean distance difference: 3.8571, Final distance difference: 1.4286\n",
      "Iteration 18600, Loss: 0.7186, Accuracy: 0.7500 mean distance difference: 6.1250, Final distance difference: 1.8750\n",
      "Iteration 18700, Loss: 0.8392, Accuracy: 0.4400 mean distance difference: 9.0000, Final distance difference: 3.0000\n",
      "Iteration 18800, Loss: 0.5585, Accuracy: 0.8000 mean distance difference: 3.2000, Final distance difference: 1.0000\n",
      "Iteration 18900, Loss: 0.8425, Accuracy: 0.6889 mean distance difference: 5.2222, Final distance difference: 1.6667\n",
      "Iteration 19000, Loss: 0.7153, Accuracy: 0.8000 mean distance difference: 3.0000, Final distance difference: 1.0000\n",
      "Iteration 19100, Loss: 1.3671, Accuracy: 0.3750 mean distance difference: 10.3750, Final distance difference: 3.5000\n",
      "Iteration 19200, Loss: 0.3928, Accuracy: 0.9111 mean distance difference: 0.6667, Final distance difference: 0.4444\n",
      "Iteration 19300, Loss: 0.5849, Accuracy: 0.8000 mean distance difference: 3.4286, Final distance difference: 1.2857\n",
      "Iteration 19400, Loss: 0.2384, Accuracy: 0.9429 mean distance difference: 1.4286, Final distance difference: 0.2857\n",
      "Iteration 19500, Loss: 0.9664, Accuracy: 0.6750 mean distance difference: 5.1250, Final distance difference: 1.6250\n",
      "Iteration 19600, Loss: 0.7926, Accuracy: 0.8250 mean distance difference: 4.8750, Final distance difference: 1.1250\n",
      "Iteration 19700, Loss: 0.4146, Accuracy: 0.8444 mean distance difference: 2.1111, Final distance difference: 0.7778\n",
      "Iteration 19800, Loss: 0.6425, Accuracy: 0.8000 mean distance difference: 3.6667, Final distance difference: 1.2222\n",
      "Iteration 19900, Loss: 0.6842, Accuracy: 0.7600 mean distance difference: 4.8000, Final distance difference: 1.6000\n"
     ]
    }
   ],
   "source": [
    "import neuralprocesses.torch as nps\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "GRID_SIZE = 10\n",
    "AGENT_VIEW_SIZE = 3\n",
    "TRAJ_LENGTH = 10\n",
    "\n",
    "agnp = nps.construct_agnp(dim_x=2, dim_y=5, likelihood=\"het\").to(device)\n",
    "#gnp = nps.construct_gnp(dim_x = 2, dim_y = 5, likelihood=\"het\").to(device)\n",
    "opt = torch.optim.Adam(agnp.parameters(), lr=1e-5)\n",
    "sampler = Sampler(grid_size = GRID_SIZE, agent_view_size = AGENT_VIEW_SIZE, traj_length = TRAJ_LENGTH, fixed_goal = True)\n",
    "\n",
    "if training:\n",
    "    for i in range(20000):\n",
    "        xc, yc, xt, yt, user_params = get_batch(sampler)\n",
    "\n",
    "        #Normalization seems to be important!\n",
    "        dist = agnp(xc, yc, xt, normalize = True)\n",
    "        \n",
    "        #(batch, actions, step)\n",
    "        logits = dist.mean  \n",
    "        #(batch, actions, step)\n",
    "        log_probs = F.log_softmax(logits, dim=-2)  # Apply log softmax to get log-probabilities\n",
    "        \n",
    "        #(batch, step)\n",
    "        nll = -(log_probs * yt).sum(dim=-2)  # Sum over the class dimension\n",
    "        loss = nll.mean()\n",
    "    \n",
    "        #Calculate the KL divergence by sampling????\n",
    "        kl = calc_kl_divergence(agnp, xc, yc, xt, yt)\n",
    "        \n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            predicted = F.softmax(dist.mean, dim = -2).argmax(dim=-2)\n",
    "            targets = yt.argmax(dim=-2)\n",
    "            accuracy = (predicted == targets).float().mean()\n",
    "            traj_distances = construct_and_calc_l1_dist(targets, predicted, xc)\n",
    "            mean_distance = traj_distances.sum(dim = -1).mean()\n",
    "            print(f\"Iteration {i}, Loss: {loss.item():.4f}, Accuracy: {accuracy.item():.4f} mean distance difference: {mean_distance.item():.4f}, Final distance difference: {traj_distances[:, -1].mean().item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if training:\n",
    "  PATH = os.path.abspath(os.getcwd())\n",
    "  torch.save(agnp.state_dict(), PATH + \"/models/agnp.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "    Chain(\n",
       "        Chain(\n",
       "            SqueezeParallel(),\n",
       "            AssertNoParallel(),\n",
       "        ),\n",
       "        Copy(),\n",
       "        Parallel(\n",
       "            Chain(\n",
       "                RepeatForAggregateInputs(\n",
       "                  (coder): InputsCoder()\n",
       "                ),\n",
       "                DeterministicLikelihood(),\n",
       "            ),\n",
       "            Parallel(\n",
       "                Chain(\n",
       "                    RepeatForAggregateInputs(\n",
       "                      (coder): Attention(\n",
       "                        (encoder_x): MLP(\n",
       "                          (net): Sequential(\n",
       "                            (0): Linear(in_features=2, out_features=256, bias=True)\n",
       "                            (1): ReLU()\n",
       "                            (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "                            (3): ReLU()\n",
       "                            (4): Linear(in_features=256, out_features=256, bias=True)\n",
       "                            (5): ReLU()\n",
       "                            (6): Linear(in_features=256, out_features=256, bias=True)\n",
       "                          )\n",
       "                        )\n",
       "                        (encoder_xy): MLP(\n",
       "                          (net): Sequential(\n",
       "                            (0): Linear(in_features=7, out_features=256, bias=True)\n",
       "                            (1): ReLU()\n",
       "                            (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "                            (3): ReLU()\n",
       "                            (4): Linear(in_features=256, out_features=256, bias=True)\n",
       "                            (5): ReLU()\n",
       "                            (6): Linear(in_features=256, out_features=256, bias=True)\n",
       "                          )\n",
       "                        )\n",
       "                        (mixer): MLP(\n",
       "                          (net): Linear(in_features=256, out_features=256, bias=True)\n",
       "                        )\n",
       "                        (mlp1): MLP(\n",
       "                          (net): Linear(in_features=256, out_features=256, bias=True)\n",
       "                        )\n",
       "                        (ln1): Sequential(\n",
       "                          (0): _LambdaModule()\n",
       "                          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                          (2): _LambdaModule()\n",
       "                        )\n",
       "                        (mlp2): MLP(\n",
       "                          (net): Sequential(\n",
       "                            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "                            (1): ReLU()\n",
       "                            (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "                          )\n",
       "                        )\n",
       "                        (ln2): Sequential(\n",
       "                          (0): _LambdaModule()\n",
       "                          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                          (2): _LambdaModule()\n",
       "                        )\n",
       "                      )\n",
       "                    ),\n",
       "                    DeterministicLikelihood(),\n",
       "                ),\n",
       "            ),\n",
       "        ),\n",
       "    ),\n",
       "    Chain(\n",
       "        Concatenate(),\n",
       "        RepeatForAggregateInputs(\n",
       "          (coder): Chain(\n",
       "              MLP(\n",
       "                (net): Sequential(\n",
       "                  (0): Linear(in_features=258, out_features=512, bias=True)\n",
       "                  (1): ReLU()\n",
       "                  (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (3): ReLU()\n",
       "                  (4): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (5): ReLU()\n",
       "                  (6): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (7): ReLU()\n",
       "                  (8): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (9): ReLU()\n",
       "                  (10): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (11): ReLU()\n",
       "                  (12): Linear(in_features=512, out_features=10, bias=True)\n",
       "                )\n",
       "              ),\n",
       "              SelectFromChannels(),\n",
       "          )\n",
       "        ),\n",
       "        HeterogeneousGaussianLikelihood(epsilon=1e-06),\n",
       "        _LambdaModule(),\n",
       "    )\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not training:\n",
    "  agnp = nps.construct_agnp(dim_x = 2, dim_y = 5, likelihood = \"het\").to(device)\n",
    "  agnp.load_state_dict(torch.load('models/anp.pth'))\n",
    "\n",
    "agnp.eval().to(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions on new trajectories, and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.800000011920929\n",
      "Predictions: tensor([[0, 0, 0, 0, 2],\n",
      "        [2, 4, 4, 4, 4],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [2, 2, 4, 4, 4],\n",
      "        [0, 0, 4, 4, 4]])\n",
      "True actions: tensor([[0, 2, 0, 0, 2],\n",
      "        [2, 2, 4, 4, 4],\n",
      "        [0, 0, 0, 2, 0],\n",
      "        [2, 2, 2, 4, 4],\n",
      "        [0, 0, 0, 4, 4]])\n",
      "Manhattan distance: tensor([[0., 2., 2., 2., 2.],\n",
      "        [0., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 2., 2.],\n",
      "        [0., 0., 1., 1., 1.],\n",
      "        [0., 0., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "agnp.eval().to(\"cpu\")\n",
    "xc, yc, xt, yt, _ = get_batch(sampler, device = \"cpu\")\n",
    "dist = agnp(xc, yc, xt)\n",
    "predictions = F.softmax(dist.mean, dim=-2).argmax(dim=-2)\n",
    "true_actions = yt.argmax(dim=-2)\n",
    "distance = construct_and_calc_l1_dist(true_actions, predictions, xc)\n",
    "\n",
    "print(f\"Accuracy: {(true_actions == predictions).float().mean()}\")\n",
    "print(f\"Predictions: {predictions}\")\n",
    "print(f\"True actions: {true_actions}\")\n",
    "print(f\"Manhattan distance: {distance}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pml2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
