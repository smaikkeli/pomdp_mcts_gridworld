{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook for training a neural process to predict simulated trajectories\n",
    "\n",
    "This notebook demonstrates how to sample user trajectories with varying user parameters from the pomdp-gridworld, and train a neural process to predict trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\") if USE_CUDA else torch.device(\"cpu\")\n",
    "training = True\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing datasets\n",
    "\n",
    "The Sampler-class is used to extract the simulated user trajectories. Below is an example data processing pipeline using the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_context_and_target(trajectories):\n",
    "  '''\n",
    "  Given a set of trajectories, build the context and target tensors \n",
    "  to feed for the neural process\n",
    "  '''\n",
    "  xc, yc, xt, yt = [], [], [], []\n",
    "  traj_length = len(trajectories[0])\n",
    "  half_point = traj_length // 2\n",
    "  \n",
    "  for i, traj in enumerate(trajectories):\n",
    "\n",
    "    #Context is each context but the current index\n",
    "    context = [trajectories[j] for j in range(len(trajectories)) if j != i]\n",
    "    \n",
    "    #All except last\n",
    "    #context += [traj[:-1]]\n",
    "    \n",
    "    #Half\n",
    "    context += [traj[:half_point]]\n",
    "    context_s, context_a = zip(*[point for c in context for point in c])\n",
    "    \n",
    "    #Only predict the last step\n",
    "    #target_s, target_a = zip(*[traj[-1]])\n",
    "    \n",
    "    #Target last half\n",
    "    target_s, target_a = zip(*traj[half_point:])\n",
    "    \n",
    "    xc.append(torch.tensor(context_s, dtype=torch.float32))\n",
    "    yc.append(torch.tensor(context_a, dtype=torch.float32))\n",
    "    xt.append(torch.tensor(target_s, dtype=torch.float32))\n",
    "    yt.append(torch.tensor(target_a, dtype=torch.float32))\n",
    "    \n",
    "  # Stack tensors\n",
    "  xc = torch.stack(xc).to(device)\n",
    "  yc = torch.stack(yc).to(device)\n",
    "  xt = torch.stack(xt).to(device)\n",
    "  yt = torch.stack(yt).to(device)\n",
    "\n",
    "  return xc, yc, xt, yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(sampler, device = device):\n",
    "  user_params = sampler.generate_user_parameters()\n",
    "\n",
    "  n_trajectories = np.random.randint(low = 5, high = 10)\n",
    "\n",
    "  trajectories = sampler.generate_user_trajectories(n_trajectories, user_params)\n",
    "\n",
    "  xc, yc, xt, yt = build_context_and_target(trajectories)\n",
    "  \n",
    "  xc = xc.permute(0,2,1).to(device)\n",
    "  yc = yc.permute(0,2,1).to(device)\n",
    "  xt = xt.permute(0,2,1).to(device)\n",
    "  yt = yt.permute(0,2,1).to(device)\n",
    "  \n",
    "  return xc, yc, xt, yt, user_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sampler can be used to define the parameters of GridWorld, which is then passed to\n",
    "the data processing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1)\n",
      "Shape of xc: torch.Size([8, 2, 75]), yc: torch.Size([8, 5, 75]), xt: torch.Size([8, 2, 5]), yt: torch.Size([8, 5, 5])\n",
      "Device of xc: cuda:0, yc: cuda:0, xt: cuda:0, yt: cuda:0\n",
      "First sequence context:\n",
      "tensor([[ 8.,  7.,  6.,  5.,  4.,  4.,  4.,  4.,  4.,  4.,  7.,  6.,  5.,  4.,\n",
      "          4.,  4.,  4.,  4.,  4.,  4.,  9.,  8.,  7.,  6.,  5.,  4.,  4.,  4.,\n",
      "          4.,  4.,  4.,  5.,  4.,  4.,  4.,  3.,  4.,  4.,  4.,  4.,  4.,  4.,\n",
      "          4.,  4.,  5.,  4.,  4.,  4.,  4.,  4.,  6.,  5.,  4.,  4.,  4.,  4.,\n",
      "          4.,  4.,  4.,  4.,  1.,  2.,  3.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,\n",
      "         10.,  9.,  9.,  8.,  7.],\n",
      "        [ 9.,  9.,  9.,  9.,  9.,  8.,  7.,  6.,  5.,  4.,  1.,  1.,  1.,  1.,\n",
      "          1.,  1.,  1.,  1.,  1.,  1.,  7.,  7.,  7.,  7.,  7.,  7.,  6.,  5.,\n",
      "          4.,  3.,  9.,  9.,  9.,  8.,  7.,  7.,  7.,  6.,  5.,  4.,  5.,  4.,\n",
      "          3.,  2.,  2.,  2.,  1.,  1.,  1.,  1.,  7.,  7.,  7.,  6.,  5.,  6.,\n",
      "          5.,  4.,  3.,  2.,  3.,  3.,  3.,  3.,  2.,  1.,  1.,  1.,  1.,  1.,\n",
      "          7.,  7.,  6.,  6.,  6.]], device='cuda:0')\n",
      "Goal position: (4, 1)\n"
     ]
    }
   ],
   "source": [
    "from src.utils.sampler import Sampler\n",
    "\n",
    "GRID_SIZE = 10\n",
    "AGENT_VIEW_SIZE = 3\n",
    "TRAJ_LENGTH = 10\n",
    "\n",
    "sampler = Sampler(grid_size = GRID_SIZE, agent_view_size = AGENT_VIEW_SIZE, traj_length = TRAJ_LENGTH, fixed_goal = True)\n",
    "xc, yc, xt, yt, user_params = get_batch(sampler)\n",
    "\n",
    "print(user_params[\"goal_position\"])\n",
    "\n",
    "print(f\"Shape of xc: {xc.shape}, yc: {yc.shape}, xt: {xt.shape}, yt: {yt.shape}\")\n",
    "print(f\"Device of xc: {xc.device}, yc: {yc.device}, xt: {xt.device}, yt: {yt.device}\")\n",
    "\n",
    "print(f\"First sequence context:\\n{xc[0]}\")\n",
    "print(f\"Goal position: {user_params['goal_position']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualitative trajectory evaluation\n",
    "\n",
    "The following functions help measuring the quality of the predicted trajectory sequences.\n",
    "\n",
    "Given the one-hot encoded actions, the trajectories are constructed either from (0,0) or from the last coordinates\n",
    "of the context set. The predictions and true trajectories are compared by the manhattan distance in each time step, which is fixed\n",
    "in the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 5]) torch.Size([8, 5])\n",
      "Predictions: tensor([[2, 2, 2, 2, 2],\n",
      "        [2, 2, 2, 2, 2],\n",
      "        [2, 2, 2, 2, 2],\n",
      "        [2, 2, 2, 2, 2],\n",
      "        [2, 2, 2, 2, 2],\n",
      "        [2, 2, 2, 2, 2],\n",
      "        [2, 2, 2, 2, 2],\n",
      "        [2, 2, 2, 2, 2]], device='cuda:0')\n",
      "True actions: tensor([[0, 2, 2, 2, 2],\n",
      "        [1, 1, 1, 4, 4],\n",
      "        [1, 1, 1, 3, 3],\n",
      "        [1, 0, 1, 2, 1],\n",
      "        [3, 4, 4, 4, 4],\n",
      "        [1, 1, 2, 2, 2],\n",
      "        [2, 2, 2, 4, 4],\n",
      "        [2, 2, 4, 4, 4]], device='cuda:0')\n",
      "Manhattan distance: tensor([[2., 2., 2., 2., 2.],\n",
      "        [2., 4., 6., 7., 8.],\n",
      "        [2., 4., 6., 6., 6.],\n",
      "        [2., 4., 6., 6., 8.],\n",
      "        [2., 3., 4., 5., 6.],\n",
      "        [2., 4., 4., 4., 4.],\n",
      "        [0., 0., 0., 1., 2.],\n",
      "        [0., 0., 1., 2., 3.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from minigrid.core.constants import DIR_TO_VEC\n",
    "#The last action corresponding to stationary\n",
    "DIR_TO_VEC =  DIR_TO_VEC + [(0, 0)]\n",
    "\n",
    "def construct_trajectory(actions, start_pos = None):\n",
    "    \"\"\"\n",
    "    Constructs a trajectory from a sequence of actions\n",
    "    \"\"\"\n",
    "    \n",
    "    mapping = torch.tensor(DIR_TO_VEC, dtype = torch.float32, device = actions.device)\n",
    "    \n",
    "    batch_size, seq_length = actions.shape\n",
    "    \n",
    "    trajectory = torch.zeros(batch_size, 2, seq_length, device = actions.device)\n",
    "    \n",
    "    if start_pos is not None:\n",
    "        prev = start_pos\n",
    "    else:\n",
    "        prev = torch.zeros(batch_size, 2, device = actions.device)\n",
    "        \n",
    "    for i in range(seq_length):\n",
    "        action_indices = actions[:, i]\n",
    "        change = mapping[action_indices]\n",
    "        trajectory[:, :, i] = prev + change\n",
    "        prev = trajectory[:, :, i]\n",
    "    \n",
    "    return trajectory\n",
    "    \n",
    "def construct_and_calc_l1_dist(yt, predictions, xc=None):\n",
    "    '''\n",
    "    Calculates the Manhattan distance between the predicted and true trajectories.\n",
    "    '''\n",
    "    # Construct trajectories\n",
    "    start_pos = xc[:, :, -1] if xc is not None else None\n",
    "    true_trajectory = construct_trajectory(yt, start_pos)\n",
    "    pred_trajectory = construct_trajectory(predictions, start_pos)\n",
    "    \n",
    "    # Calculate Manhattan distance at each timestep\n",
    "    distances = torch.abs(pred_trajectory - true_trajectory).sum(dim = 1)\n",
    "    \n",
    "    return distances\n",
    "\n",
    "# Test\n",
    "xc, yc, xt, yt, _ = get_batch(sampler)\n",
    "\n",
    "import neuralprocesses.torch as nps\n",
    "import torch.nn.functional as F\n",
    "\n",
    "agnp = nps.construct_agnp(dim_x = 2, dim_y = 5, likelihood = \"het\").to(device)\n",
    "dist = agnp(xc, yc, xt).mean\n",
    "preds = F.softmax(dist, dim=-2)\n",
    "true_actions = yt.argmax(-2)\n",
    "predictions = preds.argmax(-2)\n",
    "print(true_actions.shape, predictions.shape)\n",
    "distance = construct_and_calc_l1_dist(true_actions, predictions)\n",
    "\n",
    "\n",
    "print(f\"Predictions: {predictions}\")\n",
    "print(f\"True actions: {true_actions}\")\n",
    "print(f\"Manhattan distance: {distance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt to calculate the kl-divergence\n",
    "\n",
    "Does not seem to be currently working. The implementation is based on neuralprocesses library code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from neuralprocesses.coding import code,code_track, recode_stochastic\n",
    "from neuralprocesses.model.util import compress_contexts\n",
    "from neuralprocesses import _dispatch\n",
    "from neuralprocesses.parallel import Parallel\n",
    "from neuralprocesses.dist import AbstractDistribution\n",
    "\n",
    "@_dispatch\n",
    "def _kl(q: AbstractDistribution, p: AbstractDistribution):\n",
    "    return q.kl(p)\n",
    "\n",
    "\n",
    "@_dispatch\n",
    "def _kl(q: Parallel, p: Parallel):\n",
    "    return sum([_kl(qi, pi) for qi, pi in zip(q, p)])\n",
    "\n",
    "\n",
    "def calc_kl_divergence(model, xc, yc, xt, yt, dtype_lik = None):\n",
    "  \n",
    "    if not dtype_lik:\n",
    "      dtype_lik = torch.float32\n",
    "    \n",
    "    all_x = torch.cat([xc, xt], dim = -1)\n",
    "    all_y = torch.cat([yc, yt], dim = -1)\n",
    "      \n",
    "    xz, pz, h = code_track(model.encoder, xc, yc, xt, root=True)\n",
    "    \n",
    "    qz  = recode_stochastic(model.encoder, pz, all_x, all_y, h, root=True, dtype_lik = dtype_lik)\n",
    "    \n",
    "    kl = _kl(qz, pz)\n",
    "    \n",
    "    return kl\n",
    "\n",
    "kl = calc_kl_divergence(agnp, xc, yc, xt, yt)\n",
    "print(kl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop\n",
    "\n",
    "The training loop maximizes the log-likelihood of the categorical distribution of 5-actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 1.6102, Accuracy: 0.2857 mean distance difference: 15.8571, Final distance difference: 5.8571\n",
      "Iteration 100, Loss: 1.6093, Accuracy: 0.0571 mean distance difference: 25.0000, Final distance difference: 7.7143\n",
      "Iteration 200, Loss: 1.6094, Accuracy: 0.0444 mean distance difference: 20.3333, Final distance difference: 6.0000\n",
      "Iteration 300, Loss: 1.6153, Accuracy: 0.2286 mean distance difference: 9.7143, Final distance difference: 3.2857\n",
      "Iteration 400, Loss: 1.6022, Accuracy: 0.3714 mean distance difference: 6.7143, Final distance difference: 1.7143\n",
      "Iteration 500, Loss: 1.6081, Accuracy: 0.2667 mean distance difference: 11.1111, Final distance difference: 3.4444\n",
      "Iteration 600, Loss: 1.5895, Accuracy: 0.3714 mean distance difference: 8.7143, Final distance difference: 2.5714\n",
      "Iteration 700, Loss: 1.5692, Accuracy: 0.4500 mean distance difference: 9.2500, Final distance difference: 2.7500\n",
      "Iteration 800, Loss: 1.5353, Accuracy: 0.6500 mean distance difference: 6.3750, Final distance difference: 1.7500\n",
      "Iteration 900, Loss: 1.6130, Accuracy: 0.1667 mean distance difference: 9.0000, Final distance difference: 2.5000\n",
      "Iteration 1000, Loss: 1.5512, Accuracy: 0.4000 mean distance difference: 8.8333, Final distance difference: 2.6667\n",
      "Iteration 1100, Loss: 1.4285, Accuracy: 0.7429 mean distance difference: 5.4286, Final distance difference: 1.2857\n",
      "Iteration 1200, Loss: 1.5706, Accuracy: 0.2857 mean distance difference: 12.1429, Final distance difference: 3.5714\n",
      "Iteration 1300, Loss: 1.3667, Accuracy: 0.7250 mean distance difference: 3.8750, Final distance difference: 0.8750\n",
      "Iteration 1400, Loss: 1.6656, Accuracy: 0.2400 mean distance difference: 11.8000, Final distance difference: 3.8000\n",
      "Iteration 1500, Loss: 1.3080, Accuracy: 0.6000 mean distance difference: 5.6000, Final distance difference: 1.6000\n",
      "Iteration 1600, Loss: 1.3865, Accuracy: 0.4667 mean distance difference: 8.3333, Final distance difference: 2.6667\n",
      "Iteration 1700, Loss: 1.5207, Accuracy: 0.3333 mean distance difference: 9.3333, Final distance difference: 3.0000\n",
      "Iteration 1800, Loss: 1.3499, Accuracy: 0.5778 mean distance difference: 7.2222, Final distance difference: 1.6667\n",
      "Iteration 1900, Loss: 1.0779, Accuracy: 0.7778 mean distance difference: 4.8889, Final distance difference: 1.1111\n",
      "Iteration 2000, Loss: 1.1892, Accuracy: 0.6000 mean distance difference: 7.1667, Final distance difference: 2.0000\n",
      "Iteration 2100, Loss: 1.3526, Accuracy: 0.4571 mean distance difference: 8.4286, Final distance difference: 2.7143\n",
      "Iteration 2200, Loss: 1.6871, Accuracy: 0.3000 mean distance difference: 10.8750, Final distance difference: 3.0000\n",
      "Iteration 2300, Loss: 1.5591, Accuracy: 0.3200 mean distance difference: 9.6000, Final distance difference: 2.6000\n",
      "Iteration 2400, Loss: 1.7117, Accuracy: 0.1600 mean distance difference: 13.0000, Final distance difference: 4.2000\n",
      "Iteration 2500, Loss: 1.2219, Accuracy: 0.6000 mean distance difference: 6.5000, Final distance difference: 1.6667\n",
      "Iteration 2600, Loss: 1.3212, Accuracy: 0.5600 mean distance difference: 8.0000, Final distance difference: 1.8000\n",
      "Iteration 2700, Loss: 1.0412, Accuracy: 0.7429 mean distance difference: 4.5714, Final distance difference: 1.2857\n",
      "Iteration 2800, Loss: 1.0077, Accuracy: 0.8667 mean distance difference: 2.8333, Final distance difference: 0.6667\n",
      "Iteration 2900, Loss: 1.2400, Accuracy: 0.6000 mean distance difference: 6.7143, Final distance difference: 2.0000\n",
      "Iteration 3000, Loss: 1.3796, Accuracy: 0.4333 mean distance difference: 9.0000, Final distance difference: 2.8333\n",
      "Iteration 3100, Loss: 1.4514, Accuracy: 0.4000 mean distance difference: 9.0000, Final distance difference: 2.5556\n",
      "Iteration 3200, Loss: 1.2989, Accuracy: 0.4857 mean distance difference: 8.5714, Final distance difference: 2.2857\n",
      "Iteration 3300, Loss: 1.2335, Accuracy: 0.5500 mean distance difference: 8.3750, Final distance difference: 2.2500\n",
      "Iteration 3400, Loss: 1.8304, Accuracy: 0.0800 mean distance difference: 11.8000, Final distance difference: 3.4000\n",
      "Iteration 3500, Loss: 1.9616, Accuracy: 0.2000 mean distance difference: 10.2500, Final distance difference: 3.2500\n",
      "Iteration 3600, Loss: 1.5954, Accuracy: 0.3250 mean distance difference: 10.0000, Final distance difference: 2.8750\n",
      "Iteration 3700, Loss: 1.7117, Accuracy: 0.3333 mean distance difference: 9.5556, Final distance difference: 2.6667\n",
      "Iteration 3800, Loss: 1.3411, Accuracy: 0.4000 mean distance difference: 10.5556, Final distance difference: 3.0000\n",
      "Iteration 3900, Loss: 1.4371, Accuracy: 0.4333 mean distance difference: 7.3333, Final distance difference: 2.1667\n",
      "Iteration 4000, Loss: 1.6427, Accuracy: 0.0571 mean distance difference: 14.2857, Final distance difference: 4.4286\n",
      "Iteration 4100, Loss: 1.3902, Accuracy: 0.5000 mean distance difference: 7.6250, Final distance difference: 2.2500\n",
      "Iteration 4200, Loss: 1.1378, Accuracy: 0.6000 mean distance difference: 7.2000, Final distance difference: 2.0000\n",
      "Iteration 4300, Loss: 1.5994, Accuracy: 0.2889 mean distance difference: 11.6667, Final distance difference: 3.3333\n",
      "Iteration 4400, Loss: 1.2779, Accuracy: 0.5200 mean distance difference: 7.6000, Final distance difference: 2.0000\n",
      "Iteration 4500, Loss: 1.1569, Accuracy: 0.6500 mean distance difference: 4.8750, Final distance difference: 1.2500\n",
      "Iteration 4600, Loss: 1.3346, Accuracy: 0.4000 mean distance difference: 9.7778, Final distance difference: 3.0000\n",
      "Iteration 4700, Loss: 1.3086, Accuracy: 0.4750 mean distance difference: 7.2500, Final distance difference: 1.8750\n"
     ]
    }
   ],
   "source": [
    "import neuralprocesses.torch as nps\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "GRID_SIZE = 10\n",
    "AGENT_VIEW_SIZE = 3\n",
    "TRAJ_LENGTH = 10\n",
    "\n",
    "agnp = nps.construct_agnp(dim_x=2, dim_y=5, likelihood=\"het\").to(device)\n",
    "#gnp = nps.construct_gnp(dim_x = 2, dim_y = 5, likelihood=\"het\").to(device)\n",
    "opt = torch.optim.Adam(agnp.parameters(), lr=1e-5)\n",
    "sampler = Sampler(grid_size = GRID_SIZE, agent_view_size = AGENT_VIEW_SIZE, traj_length = TRAJ_LENGTH, fixed_goal = True)\n",
    "\n",
    "if training:\n",
    "    for i in range(20000):\n",
    "        xc, yc, xt, yt, user_params = get_batch(sampler)\n",
    "\n",
    "        #Normalization seems to be important!\n",
    "        dist = agnp(xc, yc, xt, normalize = True)\n",
    "          \n",
    "        logits = dist.mean  \n",
    "        log_probs = F.log_softmax(logits, dim=-2)  # Apply log softmax to get log-probabilities\n",
    "        \n",
    "        nll = -(log_probs * yt).sum(dim=-2)  # Sum over the class dimension\n",
    "        loss = nll.mean()\n",
    "    \n",
    "        #Calculate the KL divergence by sampling????\n",
    "        kl = calc_kl_divergence(agnp, xc, yc, xt, yt)\n",
    "        \n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            predicted = F.softmax(dist.mean, dim = -2).argmax(dim=-2)\n",
    "            targets = yt.argmax(dim=-2)\n",
    "            accuracy = (predicted == targets).float().mean()\n",
    "            traj_distances = construct_and_calc_l1_dist(targets, predicted, xc)\n",
    "            mean_distance = traj_distances.sum(dim = -1).mean()\n",
    "            print(f\"Iteration {i}, Loss: {loss.item():.4f}, Accuracy: {accuracy.item():.4f} mean distance difference: {mean_distance.item():.4f}, Final distance difference: {traj_distances[:, -1].mean().item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if training:\n",
    "  PATH = os.path.abspath(os.getcwd())\n",
    "  torch.save(agnp.state_dict(), PATH + \"/models/agnp.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "    Chain(\n",
       "        Chain(\n",
       "            SqueezeParallel(),\n",
       "            AssertNoParallel(),\n",
       "        ),\n",
       "        Copy(),\n",
       "        Parallel(\n",
       "            Chain(\n",
       "                RepeatForAggregateInputs(\n",
       "                  (coder): InputsCoder()\n",
       "                ),\n",
       "                DeterministicLikelihood(),\n",
       "            ),\n",
       "            Parallel(\n",
       "                Chain(\n",
       "                    RepeatForAggregateInputs(\n",
       "                      (coder): Attention(\n",
       "                        (encoder_x): MLP(\n",
       "                          (net): Sequential(\n",
       "                            (0): Linear(in_features=2, out_features=256, bias=True)\n",
       "                            (1): ReLU()\n",
       "                            (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "                            (3): ReLU()\n",
       "                            (4): Linear(in_features=256, out_features=256, bias=True)\n",
       "                            (5): ReLU()\n",
       "                            (6): Linear(in_features=256, out_features=256, bias=True)\n",
       "                          )\n",
       "                        )\n",
       "                        (encoder_xy): MLP(\n",
       "                          (net): Sequential(\n",
       "                            (0): Linear(in_features=7, out_features=256, bias=True)\n",
       "                            (1): ReLU()\n",
       "                            (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "                            (3): ReLU()\n",
       "                            (4): Linear(in_features=256, out_features=256, bias=True)\n",
       "                            (5): ReLU()\n",
       "                            (6): Linear(in_features=256, out_features=256, bias=True)\n",
       "                          )\n",
       "                        )\n",
       "                        (mixer): MLP(\n",
       "                          (net): Linear(in_features=256, out_features=256, bias=True)\n",
       "                        )\n",
       "                        (mlp1): MLP(\n",
       "                          (net): Linear(in_features=256, out_features=256, bias=True)\n",
       "                        )\n",
       "                        (ln1): Sequential(\n",
       "                          (0): _LambdaModule()\n",
       "                          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                          (2): _LambdaModule()\n",
       "                        )\n",
       "                        (mlp2): MLP(\n",
       "                          (net): Sequential(\n",
       "                            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "                            (1): ReLU()\n",
       "                            (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "                          )\n",
       "                        )\n",
       "                        (ln2): Sequential(\n",
       "                          (0): _LambdaModule()\n",
       "                          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                          (2): _LambdaModule()\n",
       "                        )\n",
       "                      )\n",
       "                    ),\n",
       "                    DeterministicLikelihood(),\n",
       "                ),\n",
       "            ),\n",
       "        ),\n",
       "    ),\n",
       "    Chain(\n",
       "        Concatenate(),\n",
       "        RepeatForAggregateInputs(\n",
       "          (coder): Chain(\n",
       "              MLP(\n",
       "                (net): Sequential(\n",
       "                  (0): Linear(in_features=258, out_features=512, bias=True)\n",
       "                  (1): ReLU()\n",
       "                  (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (3): ReLU()\n",
       "                  (4): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (5): ReLU()\n",
       "                  (6): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (7): ReLU()\n",
       "                  (8): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (9): ReLU()\n",
       "                  (10): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (11): ReLU()\n",
       "                  (12): Linear(in_features=512, out_features=10, bias=True)\n",
       "                )\n",
       "              ),\n",
       "              SelectFromChannels(),\n",
       "          )\n",
       "        ),\n",
       "        HeterogeneousGaussianLikelihood(epsilon=1e-06),\n",
       "        _LambdaModule(),\n",
       "    )\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not training:\n",
    "  agnp = nps.construct_agnp(dim_x = 2, dim_y = 5, likelihood = \"het\").to(device)\n",
    "  agnp.load_state_dict(torch.load('models/anp.pth'))\n",
    "\n",
    "agnp.eval().to(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions on new trajectories, and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agnp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43magnp\u001b[49m\u001b[38;5;241m.\u001b[39meval()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m xc, yc, xt, yt, _ \u001b[38;5;241m=\u001b[39m get_batch(grid_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, agent_view_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, traj_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m7\u001b[39m, device \u001b[38;5;241m=\u001b[39m device)\n\u001b[1;32m      3\u001b[0m dist \u001b[38;5;241m=\u001b[39m agnp(xc, yc, xt)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'agnp' is not defined"
     ]
    }
   ],
   "source": [
    "agnp.eval().to(\"cpu\")\n",
    "xc, yc, xt, yt, _ = get_batch(grid_size = 10, agent_view_size = 3, traj_length = 7, device = device)\n",
    "dist = agnp(xc, yc, xt)\n",
    "preds = F.softmax(dist.mean, dim=-2). argmax(dim=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0188],\n",
       "          [0.0234],\n",
       "          [0.1705],\n",
       "          [0.0986],\n",
       "          [0.6886]],\n",
       " \n",
       "         [[0.0190],\n",
       "          [0.0236],\n",
       "          [0.1710],\n",
       "          [0.0991],\n",
       "          [0.6872]],\n",
       " \n",
       "         [[0.0196],\n",
       "          [0.0243],\n",
       "          [0.1725],\n",
       "          [0.1004],\n",
       "          [0.6833]],\n",
       " \n",
       "         [[0.0188],\n",
       "          [0.0234],\n",
       "          [0.1705],\n",
       "          [0.0986],\n",
       "          [0.6886]],\n",
       " \n",
       "         [[0.0188],\n",
       "          [0.0234],\n",
       "          [0.1705],\n",
       "          [0.0986],\n",
       "          [0.6886]]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [1.]],\n",
       " \n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [1.],\n",
       "          [0.]],\n",
       " \n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [1.],\n",
       "          [0.]],\n",
       " \n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [1.]],\n",
       " \n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [1.]]]))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(dist.mean, dim=-2), yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmean\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margmax(), yt[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mean' is not defined"
     ]
    }
   ],
   "source": [
    "mean[0].argmax(), yt[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following is a copy from the relational_neural_process githu\n",
    "\n",
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNPDeterministicEncoder(nn.Module):\n",
    "    def __init__(self, sizes):\n",
    "        super(CNPDeterministicEncoder, self).__init__()\n",
    "        self.linears = nn.ModuleList()\n",
    "        for i in range(len(sizes) - 1):\n",
    "            self.linears.append(nn.Linear(sizes[i], sizes[i + 1]))\n",
    "\n",
    "    def forward(self, context_x, context_y):\n",
    "        \"\"\"\n",
    "        Encode training set as one vector representation\n",
    "\n",
    "        Args:\n",
    "            context_x: batch_size x set_size x feature_dim_x\n",
    "            context_y: batch_size x set_size x feature_dim_y\n",
    "\n",
    "        Returns: representation: batch_size x representation_size:\n",
    "        \"\"\"\n",
    "\n",
    "        encoder_input = torch.cat((context_x, context_y), dim = -1)\n",
    "        batch_size, set_size, filter_size = encoder_input.shape\n",
    "        x = encoder_input.view(batch_size * set_size, -1)\n",
    "        for i, linear in enumerate(self.linears[:-1]):\n",
    "            x = torch.relu(linear(x))\n",
    "        x = self.linears[-1](x)\n",
    "        x = x.view(batch_size, set_size, -1)\n",
    "        representation = x.sum(dim=1)\n",
    "        return representation\n",
    "            \n",
    "class CNPDeterministicDecoder(nn.Module):\n",
    "    def __init__(self, sizes):\n",
    "        super(CNPDeterministicDecoder, self).__init__()\n",
    "        self.linears = nn.ModuleList()\n",
    "        for i in range(len(sizes) - 1):\n",
    "            self.linears.append(nn.Linear(sizes[i], sizes[i + 1]))\n",
    "\n",
    "    def forward(self, representation, target_x):\n",
    "        \"\"\"\n",
    "        Take representation representation of current training set, and a target input x,\n",
    "        return the predictive distribution at x (Gaussian with mean mu and scale sigma)\n",
    "\n",
    "        Args:\n",
    "            representation: batch_size x representation_size\n",
    "            target_x: batch_size x set_size x d\n",
    "        \"\"\"\n",
    "        batch_size, set_size, d = target_x.shape\n",
    "        \n",
    "        if representation is None:        \n",
    "            input = target_x            \n",
    "        else:\n",
    "            representation = representation.unsqueeze(1).repeat([1, set_size, 1])\n",
    "            input = torch.cat((representation, target_x), dim=-1)\n",
    "        \n",
    "        #All rows\n",
    "        x = input.view(batch_size * set_size, -1)\n",
    "        for linear in self.linears[:-1]:\n",
    "            x = torch.relu(linear(x))\n",
    "        logits = self.linears[-1](x)\n",
    "        logits = logits.view(batch_size, set_size, -1)\n",
    "        probs = F.softmax(logits, dim = -1)\n",
    "\n",
    "        dist = torch.distributions.categorical.Categorical(probs = probs)\n",
    "        return dist, probs, logits\n",
    "    \n",
    "        '''\n",
    "        mu, log_sigma = torch.split(out, 1, dim = -1)\n",
    "        sigma = 0.01 + 0.99 * torch.nn.functional.softplus(log_sigma)\n",
    "        dist = torch.distributions.normal.Normal(loc=mu, scale=sigma)\n",
    "        '''\n",
    "\n",
    "class CNPDeterministicModel(nn.Module):\n",
    "    def __init__(self, encoder_size, decoder_size):\n",
    "        super(CNPDeterministicModel, self).__init__()\n",
    "        self._encoder = CNPDeterministicEncoder(encoder_size)\n",
    "        self._decoder = CNPDeterministicDecoder(decoder_size)\n",
    "\n",
    "\n",
    "    def forward(self, query, target_y = None):\n",
    "        (context_x, context_y), target_x = query\n",
    "        representation = self._encoder(context_x, context_y)\n",
    "        dist, probs, logits = self._decoder(representation, target_x)\n",
    "\n",
    "        log_p = None\n",
    "        if target_y is not None:\n",
    "            #Reverse one hot encoding on target_y\n",
    "            target_y = torch.argmax(target_y, dim = -1)\n",
    "            log_p = dist.log_prob(target_y)\n",
    "\n",
    "        return log_p, probs, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNPDeterministicModel(\n",
       "  (_encoder): CNPDeterministicEncoder(\n",
       "    (linears): ModuleList(\n",
       "      (0): Linear(in_features=6, out_features=128, bias=True)\n",
       "      (1-2): 2 x Linear(in_features=128, out_features=128, bias=True)\n",
       "      (3): Linear(in_features=128, out_features=258, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (_decoder): CNPDeterministicDecoder(\n",
       "    (linears): ModuleList(\n",
       "      (0): Linear(in_features=260, out_features=128, bias=True)\n",
       "      (1-2): 2 x Linear(in_features=128, out_features=128, bias=True)\n",
       "      (3): Linear(in_features=128, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import neuralprocesses.torch as nps\n",
    "\n",
    "d_x, d_in, representation_size, d_out, hidden_size = 2, 6, 258, 4, 128\n",
    "encoder_sizes = [d_in, hidden_size, hidden_size, hidden_size, representation_size]\n",
    "decoder_sizes = [representation_size + d_x, hidden_size, hidden_size, hidden_size, d_out]\n",
    "\n",
    "model = CNPDeterministicModel(encoder_size=encoder_sizes, decoder_size=decoder_sizes)\n",
    "model.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pml2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
