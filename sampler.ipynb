{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from src.grid_world import GridWorld\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\") if USE_CUDA else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "- Sample (state, action)-pairs. Split them to context and target sets!\n",
    "- Figure out how to split them correctly, what differences are there brtween\n",
    "- Train a neural process using the HIIT library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulator\n",
    "\n",
    "Global Fixed Parameters:\n",
    "- Grid_size int: side lengths of the grid\n",
    "- Agent_view_size int: side length of the agents view area\n",
    "\n",
    "User specific parameters\n",
    "\n",
    "Fixed\n",
    "\n",
    "- Agent_pos (int, int): Agent's initial position\n",
    "- Goal_pos (int, int): Goal's initial position\n",
    "\n",
    "Change each trial\n",
    "\n",
    "- Mode_densities: \n",
    "\n",
    "Keep fixed:\n",
    "Grid size\n",
    "Agent_view_size\n",
    "Mode_densities\n",
    "\n",
    "Sample:\n",
    "Goal_pos,\n",
    "Agent_pos\n",
    "\n",
    "User parameters:\n",
    "Number of belief modes\n",
    "Distribution of the belief modes (Dirichlet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5]\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "def sample_mode_densities(max_modes = 3, total_density = 0.9):\n",
    "  '''\n",
    "  Samples a list of mode densities that guide the agent's\n",
    "  behavior.\n",
    "  '''\n",
    "  num_modes = np.random.randint(1, max_modes + 1)\n",
    "  densities = np.random.dirichlet(np.ones(num_modes)) * total_density\n",
    "  return list(densities)\n",
    "\n",
    "test_sample = sample_mode_densities(max_modes = 5, total_density = 0.5)\n",
    "print(test_sample)\n",
    "print(np.sum(test_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mode_densities': [0.05038294008326661, 0.8496170599167334], 'mode_positions': array([[5, 5],\n",
      "       [0, 8]])}\n"
     ]
    }
   ],
   "source": [
    "def generate_user_parameters(grid_size, mode_params = None):\n",
    "  '''\n",
    "  Generates a set of parameters that define the user's behavior.\n",
    "  '''\n",
    "  \n",
    "  mode_densities = None\n",
    "  if mode_params is None:\n",
    "    mode_densities = sample_mode_densities()\n",
    "  else:\n",
    "    mode_densities = sample_mode_densities(mode_params)\n",
    "  \n",
    "  mode_positions = np.random.randint(0, grid_size, (len(mode_densities), 2))\n",
    "  \n",
    "  return {\n",
    "    'mode_densities': mode_densities,\n",
    "    'mode_positions': mode_positions,\n",
    "  }\n",
    "  \n",
    "test_param = generate_user_parameters(10)\n",
    "print(test_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[((7, 9), [0, 0, 1, 0]), ((7, 8), [0, 0, 1, 0]), ((7, 7), [0, 0, 1, 0]), ((7, 6), [0, 0, 1, 0]), ((7, 5), [0, 1, 0, 0]), ((8, 5), [1, 0, 0, 0]), ((7, 5), [1, 0, 0, 0]), ((6, 5), [1, 0, 0, 0]), ((5, 5), [1, 0, 0, 0]), ((4, 5), [1, 0, 0, 0])]\n"
     ]
    }
   ],
   "source": [
    "def generate_user_trajectories(num_trajectories, grid_size, agent_view_size, user_params, traj_length = None):\n",
    "  mode_densities = user_params['mode_densities']\n",
    "  mode_positions = user_params['mode_positions']\n",
    "  \n",
    "  env = GridWorld(render_mode = \"rgb_array\", size = grid_size, agent_view_size = agent_view_size, mode_densities = mode_densities, mode_positions=mode_positions)\n",
    "  \n",
    "  trajectories = []\n",
    "  \n",
    "  while len(trajectories) < num_trajectories:\n",
    "    trajectory = []\n",
    "    \n",
    "    obs = env.reset()\n",
    "    state = obs[0]['agent_pos']\n",
    "    \n",
    "    done = False\n",
    "\n",
    "    while not done and len(trajectory) < traj_length:\n",
    "\n",
    "      action = env.max_neighboring_reward()\n",
    "\n",
    "      action_onehot = [0 for _ in range(env.action_space.n)]\n",
    "      action_onehot[action] = 1\n",
    "\n",
    "      trajectory.append((state, action_onehot))\n",
    "\n",
    "      next_obs, _, done, truncated, _ = env.step(action)\n",
    "      state = next_obs['agent_pos']\n",
    "      \n",
    "      done = done or truncated\n",
    "\n",
    "    trajectory.append((state, action_onehot))\n",
    "\n",
    "    if len(trajectory) < traj_length:\n",
    "      continue\n",
    "\n",
    "    trajectories.append(trajectory[:traj_length])\n",
    "    \n",
    "  return trajectories\n",
    "\n",
    "num_traj = 200\n",
    "grid_size = 10\n",
    "agent_view_size = 5\n",
    "traj_length  = 10\n",
    "user_params = generate_user_parameters(grid_size)\n",
    "trajectories = generate_user_trajectories(num_traj, grid_size, agent_view_size, user_params, traj_length = traj_length)\n",
    "print(np.all([len(traj) == traj_length for traj in trajectories]))\n",
    "print(trajectories[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_trajectory_half(trajectory):\n",
    "  '''\n",
    "  Splits a trajectory into two halves.\n",
    "  '''\n",
    "  half = len(trajectory) // 2\n",
    "  return trajectory[:half], trajectory[half:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "\n",
    "def context_and_target(dataset):\n",
    "    num_traj = len(dataset)\n",
    "    xc, yc, xt, yt = [], [], [], []\n",
    "\n",
    "    for i in range(num_traj):\n",
    "        # Pick one as target and split it\n",
    "        context_part, target_part = split_trajectory_half(dataset[i])\n",
    "\n",
    "        # Choose the ids of past context trajectories\n",
    "        past_context_ids = list(range(i)) + list(range(i+1, num_traj))\n",
    "\n",
    "        # Generate all permutations of past context ids\n",
    "        all_permutations = list(permutations(past_context_ids))\n",
    "\n",
    "        #Choose a subset of permutations\n",
    "        selected_permutations = np.random.choice(len(all_permutations),\n",
    "                                                 size=min(5, len(all_permutations)),\n",
    "                                                 replace=False)\n",
    "        \n",
    "        # Generate multiple tasks from the chosen target set and different context\n",
    "        for p_idx in selected_permutations:\n",
    "            p = list(all_permutations[p_idx])\n",
    "            \n",
    "            past_contexts = [dataset[j] for j in p]\n",
    "\n",
    "            full_context = past_contexts + [context_part]\n",
    "\n",
    "            # Separate states and actions for context and target\n",
    "\n",
    "            context_s = torch.tensor([state for traj in full_context for state, _ in traj], dtype = torch.float32)\n",
    "            context_a = torch.tensor([action for traj in full_context for _, action in traj], dtype = torch.float32)\n",
    "            target_s = torch.tensor([state for state, _ in target_part], dtype = torch.float32)\n",
    "            target_a = torch.tensor([action for _, action in target_part], dtype = torch.float32)\n",
    "\n",
    "            xc.append(context_s)\n",
    "            yc.append(context_a)\n",
    "            xt.append(target_s)\n",
    "            yt.append(target_a)\n",
    "\n",
    "    xc = torch.stack(xc, dim = 0)\n",
    "    yc = torch.stack(yc, dim = 0)\n",
    "    xt = torch.stack(xt, dim = 0)\n",
    "    yt = torch.stack(yt, dim = 0)\n",
    "\n",
    "    return xc, yc, xt, yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(grid_size = 10, agent_view_size = 5, traj_length = 10):\n",
    "\n",
    "  user_params = generate_user_parameters(grid_size)\n",
    "  \n",
    "  num_trajectories = np.random.randint(1, 11)\n",
    "  \n",
    "  trajectories = generate_user_trajectories(num_trajectories, grid_size, agent_view_size, user_params, traj_length)\n",
    "  \n",
    "  batch = context_and_target(trajectories)\n",
    "  \n",
    "  return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRID_SIZE = 10\n",
    "AGENT_VIEW_SIZE = 3\n",
    "N_USERS = 100\n",
    "TRAJ_LENGTH = 10\n",
    "\n",
    "batch = generate_batch(grid_size = GRID_SIZE, agent_view_size = AGENT_VIEW_SIZE, traj_length = TRAJ_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 35, 2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_CNP = True\n",
    "\n",
    "TRAINING_ITERATIONS =  int(1e4)\n",
    "PLOT_AFTER = int(1e3)\n",
    "USE_TEMPERATURE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Neural Process\n",
    "\n",
    "CNPs take in pairs (x, y)\n",
    "\n",
    "## The following is a copy from the relational_neural_process github\n",
    "\n",
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNPDeterministicEncoder(nn.Module):\n",
    "    def __init__(self, sizes):\n",
    "        super(CNPDeterministicEncoder, self).__init__()\n",
    "        self.linears = nn.ModuleList()\n",
    "        for i in range(len(sizes) - 1):\n",
    "            self.linears.append(nn.Linear(sizes[i], sizes[i + 1]))\n",
    "\n",
    "    def forward(self, context_x, context_y):\n",
    "        \"\"\"\n",
    "        Encode training set as one vector representation\n",
    "\n",
    "        Args:\n",
    "            context_x: batch_size x set_size x feature_dim_x\n",
    "            context_y: batch_size x set_size x feature_dim_y\n",
    "\n",
    "        Returns: representation: batch_size x representation_size:\n",
    "        \"\"\"\n",
    "\n",
    "        encoder_input = torch.cat((context_x, context_y), dim = -1)\n",
    "        batch_size, set_size, filter_size = encoder_input.shape\n",
    "        x = encoder_input.view(batch_size * set_size, -1)\n",
    "        for i, linear in enumerate(self.linears[:-1]):\n",
    "            x = torch.relu(linear(x))\n",
    "        x = self.linears[-1](x)\n",
    "        x = x.view(batch_size, set_size, -1)\n",
    "        representation = x.sum(dim=1)\n",
    "        return representation\n",
    "            \n",
    "class CNPDeterministicDecoder(nn.Module):\n",
    "    def __init__(self, sizes):\n",
    "        super(CNPDeterministicDecoder, self).__init__()\n",
    "        self.linears = nn.ModuleList()\n",
    "        for i in range(len(sizes) - 1):\n",
    "            self.linears.append(nn.Linear(sizes[i], sizes[i + 1]))\n",
    "\n",
    "    def forward(self, representation, target_x):\n",
    "        \"\"\"\n",
    "        Take representation representation of current training set, and a target input x,\n",
    "        return the predictive distribution at x (Gaussian with mean mu and scale sigma)\n",
    "\n",
    "        Args:\n",
    "            representation: batch_size x representation_size\n",
    "            target_x: batch_size x set_size x d\n",
    "        \"\"\"\n",
    "        batch_size, set_size, d = target_x.shape\n",
    "        \n",
    "        if representation is None:        \n",
    "            input = target_x            \n",
    "        else:\n",
    "            representation = representation.unsqueeze(1).repeat([1, set_size, 1])\n",
    "            input = torch.cat((representation, target_x), dim=-1)\n",
    "        \n",
    "        #All rows\n",
    "        x = input.view(batch_size * set_size, -1)\n",
    "        for linear in self.linears[:-1]:\n",
    "            x = torch.relu(linear(x))\n",
    "        logits = self.linears[-1](x)\n",
    "        logits = logits.view(batch_size, set_size, -1)\n",
    "        probs = F.softmax(logits, dim = -1)\n",
    "\n",
    "        dist = torch.distributions.categorical.Categorical(probs = probs)\n",
    "        return dist, probs, logits\n",
    "    \n",
    "        '''\n",
    "        mu, log_sigma = torch.split(out, 1, dim = -1)\n",
    "        sigma = 0.01 + 0.99 * torch.nn.functional.softplus(log_sigma)\n",
    "        dist = torch.distributions.normal.Normal(loc=mu, scale=sigma)\n",
    "        '''\n",
    "\n",
    "class CNPDeterministicModel(nn.Module):\n",
    "    def __init__(self, encoder_size, decoder_size):\n",
    "        super(CNPDeterministicModel, self).__init__()\n",
    "        self._encoder = CNPDeterministicEncoder(encoder_size)\n",
    "        self._decoder = CNPDeterministicDecoder(decoder_size)\n",
    "\n",
    "\n",
    "    def forward(self, query, target_y = None):\n",
    "        (context_x, context_y), target_x = query\n",
    "        representation = self._encoder(context_x, context_y)\n",
    "        dist, probs, logits = self._decoder(representation, target_x)\n",
    "\n",
    "        log_p = None\n",
    "        if target_y is not None:\n",
    "            #Reverse one hot encoding on target_y\n",
    "            target_y = torch.argmax(target_y, dim = -1)\n",
    "            log_p = dist.log_prob(target_y)\n",
    "\n",
    "        return log_p, probs, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuralprocesses.torch as nps\n",
    "\n",
    "d_x, d_in, representation_size, d_out, hidden_size = 2, 6, 258, 4, 128\n",
    "encoder_sizes = [d_in, hidden_size, hidden_size, hidden_size, representation_size]\n",
    "decoder_sizes = [representation_size + d_x, hidden_size, hidden_size, hidden_size, d_out]\n",
    "\n",
    "model = CNPDeterministicModel(encoder_size=encoder_sizes, decoder_size=decoder_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0, avg_loss = 1.4590564966201782\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[175], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(TRAINING_ITERATIONS):\n\u001b[1;32m      6\u001b[0m     opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 8\u001b[0m     xc, yc, xt, yt \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrid_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mGRID_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent_view_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mAGENT_VIEW_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraj_length\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mTRAJ_LENGTH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     query \u001b[38;5;241m=\u001b[39m (xc, yc), xt\n\u001b[1;32m     12\u001b[0m     log_p, prob, logits \u001b[38;5;241m=\u001b[39m model(query, yt)\n",
      "Cell \u001b[0;32mIn[158], line 7\u001b[0m, in \u001b[0;36mgenerate_batch\u001b[0;34m(grid_size, agent_view_size, traj_length)\u001b[0m\n\u001b[1;32m      3\u001b[0m user_params \u001b[38;5;241m=\u001b[39m generate_user_parameters(grid_size)\n\u001b[1;32m      5\u001b[0m num_trajectories \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m11\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m trajectories \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_user_trajectories\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_trajectories\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent_view_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraj_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m batch \u001b[38;5;241m=\u001b[39m context_and_target(trajectories)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batch\n",
      "Cell \u001b[0;32mIn[155], line 18\u001b[0m, in \u001b[0;36mgenerate_user_trajectories\u001b[0;34m(num_trajectories, grid_size, agent_view_size, user_params, traj_length)\u001b[0m\n\u001b[1;32m     15\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[0;32m---> 18\u001b[0m   action \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_neighboring_reward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m   action_onehot \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(env\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mn)]\n\u001b[1;32m     21\u001b[0m   action_onehot[action] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Aalto/internship2024/non_stationary/src/grid_world.py:63\u001b[0m, in \u001b[0;36mGridWorld.max_neighboring_reward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     61\u001b[0m best_action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(Actions)):\n\u001b[0;32m---> 63\u001b[0m     env_copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m     obs, reward, terminated, truncated, _ \u001b[38;5;241m=\u001b[39m env_copy\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m reward \u001b[38;5;241m>\u001b[39m best_reward:\n",
      "File \u001b[0;32m~/Documents/Aalto/internship2024/non_stationary/src/grid_world.py:325\u001b[0m, in \u001b[0;36mGridWorld.copy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcopy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    324\u001b[0m     new_env \u001b[38;5;241m=\u001b[39m GridWorld(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m, start_pos\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_pos, agent_view_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_view_size)\n\u001b[0;32m--> 325\u001b[0m     new_env\u001b[38;5;241m.\u001b[39mgrid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m     new_env\u001b[38;5;241m.\u001b[39mstep_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_count\n\u001b[1;32m    327\u001b[0m     new_env\u001b[38;5;241m.\u001b[39magent_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_dir\n",
      "File \u001b[0;32m~/Documents/Aalto/internship2024/non_stationary/src/core/grid.py:26\u001b[0m, in \u001b[0;36mModifiedGrid.copy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcopy\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModifiedGrid\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deepcopy\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pml/lib/python3.10/copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[0;32m~/anaconda3/envs/pml/lib/python3.10/copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[0;32m--> 271\u001b[0m         state \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    273\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "File \u001b[0;32m~/anaconda3/envs/pml/lib/python3.10/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/pml/lib/python3.10/copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m~/anaconda3/envs/pml/lib/python3.10/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/pml/lib/python3.10/copy.py:206\u001b[0m, in \u001b[0;36m_deepcopy_list\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    204\u001b[0m append \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mappend\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x:\n\u001b[0;32m--> 206\u001b[0m     append(\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m~/anaconda3/envs/pml/lib/python3.10/copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[0;32m~/anaconda3/envs/pml/lib/python3.10/copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[0;32m--> 271\u001b[0m         state \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    273\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), 1e-3)\n",
    "\n",
    "total_loss = []\n",
    "\n",
    "for i in range(TRAINING_ITERATIONS):\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    xc, yc, xt, yt = generate_batch(grid_size = GRID_SIZE, agent_view_size = AGENT_VIEW_SIZE, traj_length = TRAJ_LENGTH)\n",
    "\n",
    "    query = (xc, yc), xt\n",
    "\n",
    "    log_p, prob, logits = model(query, yt)\n",
    "\n",
    "    loss = -log_p.mean()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "    total_loss.append(loss.item())\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        avg_loss = np.mean(total_loss)\n",
    "        print(f\"iter: {i}, avg_loss = {avg_loss}\")\n",
    "        total_loss = []\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20, 35, 2])\n",
      "tensor([[[[ 0.0329,  0.0324,  0.0328,  0.0325,  0.0327],\n",
      "          [ 0.0405,  0.0395,  0.0402,  0.0392,  0.0399],\n",
      "          [-0.0140, -0.0133, -0.0139, -0.0137, -0.0139],\n",
      "          [ 0.0102,  0.0101,  0.0101,  0.0101,  0.0101]],\n",
      "\n",
      "         [[ 0.0331,  0.0325,  0.0330,  0.0326,  0.0329],\n",
      "          [ 0.0401,  0.0392,  0.0399,  0.0390,  0.0396],\n",
      "          [-0.0141, -0.0133, -0.0140, -0.0138, -0.0140],\n",
      "          [ 0.0110,  0.0108,  0.0109,  0.0108,  0.0109]],\n",
      "\n",
      "         [[ 0.0321,  0.0326,  0.0322,  0.0326,  0.0324],\n",
      "          [ 0.0412,  0.0395,  0.0407,  0.0391,  0.0401],\n",
      "          [-0.0121, -0.0117, -0.0121, -0.0120, -0.0121],\n",
      "          [ 0.0122,  0.0118,  0.0121,  0.0120,  0.0120]],\n",
      "\n",
      "         [[ 0.0322,  0.0322,  0.0323,  0.0324,  0.0324],\n",
      "          [ 0.0408,  0.0395,  0.0403,  0.0391,  0.0399],\n",
      "          [-0.0121, -0.0119, -0.0120, -0.0121, -0.0120],\n",
      "          [ 0.0116,  0.0110,  0.0114,  0.0111,  0.0113]],\n",
      "\n",
      "         [[ 0.0325,  0.0322,  0.0324,  0.0323,  0.0323],\n",
      "          [ 0.0408,  0.0396,  0.0405,  0.0395,  0.0402],\n",
      "          [-0.0141, -0.0131, -0.0140, -0.0136, -0.0139],\n",
      "          [ 0.0105,  0.0103,  0.0104,  0.0104,  0.0104]],\n",
      "\n",
      "         [[ 0.0331,  0.0328,  0.0331,  0.0328,  0.0331],\n",
      "          [ 0.0391,  0.0389,  0.0392,  0.0389,  0.0394],\n",
      "          [-0.0133, -0.0125, -0.0129, -0.0125, -0.0125],\n",
      "          [ 0.0125,  0.0122,  0.0122,  0.0122,  0.0122]],\n",
      "\n",
      "         [[ 0.0333,  0.0326,  0.0332,  0.0326,  0.0330],\n",
      "          [ 0.0405,  0.0396,  0.0404,  0.0396,  0.0405],\n",
      "          [-0.0138, -0.0127, -0.0133, -0.0127, -0.0128],\n",
      "          [ 0.0104,  0.0103,  0.0103,  0.0103,  0.0103]],\n",
      "\n",
      "         [[ 0.0327,  0.0327,  0.0328,  0.0327,  0.0327],\n",
      "          [ 0.0401,  0.0391,  0.0399,  0.0391,  0.0402],\n",
      "          [-0.0123, -0.0118, -0.0119, -0.0118, -0.0116],\n",
      "          [ 0.0117,  0.0111,  0.0115,  0.0111,  0.0113]],\n",
      "\n",
      "         [[ 0.0323,  0.0319,  0.0321,  0.0319,  0.0318],\n",
      "          [ 0.0403,  0.0393,  0.0402,  0.0393,  0.0404],\n",
      "          [-0.0127, -0.0123, -0.0124, -0.0123, -0.0120],\n",
      "          [ 0.0104,  0.0098,  0.0102,  0.0098,  0.0102]],\n",
      "\n",
      "         [[ 0.0324,  0.0317,  0.0322,  0.0317,  0.0320],\n",
      "          [ 0.0404,  0.0395,  0.0403,  0.0395,  0.0404],\n",
      "          [-0.0140, -0.0129, -0.0135, -0.0129, -0.0130],\n",
      "          [ 0.0098,  0.0098,  0.0097,  0.0098,  0.0097]],\n",
      "\n",
      "         [[ 0.0334,  0.0333,  0.0335,  0.0333,  0.0335],\n",
      "          [ 0.0403,  0.0406,  0.0407,  0.0408,  0.0409],\n",
      "          [-0.0131, -0.0116, -0.0126, -0.0110, -0.0126],\n",
      "          [ 0.0106,  0.0102,  0.0108,  0.0102,  0.0110]],\n",
      "\n",
      "         [[ 0.0330,  0.0329,  0.0329,  0.0329,  0.0329],\n",
      "          [ 0.0401,  0.0404,  0.0405,  0.0406,  0.0407],\n",
      "          [-0.0133, -0.0119, -0.0127, -0.0115, -0.0126],\n",
      "          [ 0.0105,  0.0102,  0.0105,  0.0100,  0.0106]],\n",
      "\n",
      "         [[ 0.0321,  0.0312,  0.0318,  0.0309,  0.0318],\n",
      "          [ 0.0404,  0.0410,  0.0409,  0.0415,  0.0412],\n",
      "          [-0.0125, -0.0116, -0.0121, -0.0112, -0.0120],\n",
      "          [ 0.0101,  0.0097,  0.0101,  0.0096,  0.0102]],\n",
      "\n",
      "         [[ 0.0316,  0.0309,  0.0313,  0.0307,  0.0313],\n",
      "          [ 0.0407,  0.0412,  0.0412,  0.0416,  0.0415],\n",
      "          [-0.0127, -0.0116, -0.0121, -0.0112, -0.0120],\n",
      "          [ 0.0094,  0.0090,  0.0095,  0.0090,  0.0097]],\n",
      "\n",
      "         [[ 0.0331,  0.0327,  0.0330,  0.0326,  0.0330],\n",
      "          [ 0.0397,  0.0401,  0.0399,  0.0402,  0.0401],\n",
      "          [-0.0137, -0.0124, -0.0131, -0.0120, -0.0130],\n",
      "          [ 0.0104,  0.0102,  0.0103,  0.0101,  0.0104]],\n",
      "\n",
      "         [[ 0.0302,  0.0303,  0.0303,  0.0302,  0.0304],\n",
      "          [ 0.0430,  0.0427,  0.0426,  0.0428,  0.0422],\n",
      "          [-0.0110, -0.0114, -0.0115, -0.0113, -0.0120],\n",
      "          [ 0.0081,  0.0082,  0.0081,  0.0084,  0.0081]],\n",
      "\n",
      "         [[ 0.0306,  0.0309,  0.0309,  0.0309,  0.0311],\n",
      "          [ 0.0433,  0.0431,  0.0429,  0.0433,  0.0425],\n",
      "          [-0.0109, -0.0113, -0.0114, -0.0114, -0.0119],\n",
      "          [ 0.0091,  0.0093,  0.0091,  0.0095,  0.0091]],\n",
      "\n",
      "         [[ 0.0310,  0.0312,  0.0312,  0.0312,  0.0314],\n",
      "          [ 0.0432,  0.0430,  0.0428,  0.0432,  0.0425],\n",
      "          [-0.0114, -0.0117, -0.0119, -0.0116, -0.0124],\n",
      "          [ 0.0080,  0.0081,  0.0080,  0.0083,  0.0080]],\n",
      "\n",
      "         [[ 0.0302,  0.0304,  0.0304,  0.0304,  0.0307],\n",
      "          [ 0.0434,  0.0431,  0.0429,  0.0432,  0.0426],\n",
      "          [-0.0113, -0.0116, -0.0117, -0.0115, -0.0121],\n",
      "          [ 0.0085,  0.0087,  0.0085,  0.0089,  0.0085]],\n",
      "\n",
      "         [[ 0.0308,  0.0309,  0.0309,  0.0309,  0.0311],\n",
      "          [ 0.0427,  0.0425,  0.0424,  0.0427,  0.0420],\n",
      "          [-0.0111, -0.0115, -0.0116, -0.0114, -0.0120],\n",
      "          [ 0.0089,  0.0092,  0.0090,  0.0093,  0.0090]]]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import neuralprocesses.torch as nps\n",
    "\n",
    "cnp = nps.construct_gnp(dim_x = 2, dim_y = 4, likelihood = \"het\")\n",
    "\n",
    "xc, yc, xt, yt = generate_batch(grid_size = GRID_SIZE, agent_view_size = AGENT_VIEW_SIZE, traj_length = TRAJ_LENGTH)\n",
    "xc = xc.unsqueeze(0)\n",
    "yc = yc.unsqueeze(0)\n",
    "xt = xt.unsqueeze(0)\n",
    "yt = yt.unsqueeze(0)\n",
    "\n",
    "print(xc.shape)\n",
    "\n",
    "xc = xc.view(1, xc.shape[1], 2, -1)\n",
    "yc = yc.view(1, yc.shape[1], 4, -1)\n",
    "xt = xt.view(1, xt.shape[1], 2, -1)\n",
    "yt = yt.view(1, yt.shape[1], 4, -1)\n",
    "\n",
    "dist = cnp(xc, yc, xt)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2., 3.],\n",
       "         [4., 5., 6.]],\n",
       "\n",
       "        [[1., 2., 3.],\n",
       "         [4., 5., 6.]],\n",
       "\n",
       "        [[1., 2., 3.],\n",
       "         [4., 5., 6.]],\n",
       "\n",
       "        [[1., 2., 3.],\n",
       "         [4., 5., 6.]],\n",
       "\n",
       "        [[1., 2., 3.],\n",
       "         [4., 5., 6.]],\n",
       "\n",
       "        [[1., 2., 3.],\n",
       "         [4., 5., 6.]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test how torch.split works\n",
    "import torch\n",
    "tensor = torch.tensor([1,2,3,4,5,6], dtype = torch.float32)\n",
    "tensor = tensor.repeat(6,1)\n",
    "tensor = tensor.view(6,2,-1)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pml2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
